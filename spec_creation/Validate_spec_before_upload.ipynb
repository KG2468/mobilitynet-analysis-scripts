{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some basic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.features as fof\n",
    "import folium.utilities as ful\n",
    "import branca.element as bre\n",
    "import json\n",
    "import geojson as gj\n",
    "import arrow\n",
    "\n",
    "import shapely.geometry as shpg\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lonlat_swap(lon_lat):\n",
    "    return list(reversed(lon_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_count(n_maps, cols):\n",
    "    rows = (n_maps / cols)\n",
    "    if (n_maps % cols != 0):\n",
    "        rows = rows + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_marker(loc, disp_color):\n",
    "    if loc[\"geometry\"][\"type\"] == \"Point\":\n",
    "        curr_latlng = lonlat_swap(loc[\"geometry\"][\"coordinates\"])\n",
    "        return folium.Marker(curr_latlng, icon=folium.Icon(color=disp_color),\n",
    "                  popup=\"%s\" % loc[\"properties\"][\"name\"])\n",
    "    elif loc[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "        assert len(loc[\"geometry\"][\"coordinates\"]) == 1,\\\n",
    "            \"Only simple polygons supported!\"\n",
    "        curr_latlng = [lonlat_swap(c) for c in loc[\"geometry\"][\"coordinates\"][0]]\n",
    "        # print(\"Returning polygon for %s\" % curr_latlng)\n",
    "        return folium.PolyLine(curr_latlng, color=disp_color, fill=disp_color,\n",
    "                  popup=\"%s\" % loc[\"properties\"][\"name\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker(loc, disp_color):\n",
    "    if type(loc) == list:\n",
    "        return [get_one_marker(l, disp_color) for l in loc]\n",
    "    else:\n",
    "        print(\"Found single entry, is this expected?\")\n",
    "        return [get_one_marker(loc, disp_color)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_to_validate = json.load(open(\"final_sfbayarea_filled_reroutes/train_bus_ebike_mtv_ucb.filled.reroute.json\"))\n",
    "sensing_configs = json.load(open(\"sensing_regimes.all.specs.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment runs from 2019-07-16T07:00:00+00:00 -> 2020-04-30T07:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment runs from %s -> %s\" % (arrow.get(spec_to_validate[\"start_ts\"]), arrow.get(spec_to_validate[\"end_ts\"])))\n",
    "start_fmt_time_to_validate = arrow.get(spec_to_validate[\"start_ts\"]).format(\"YYYY-MM-DD\")\n",
    "end_fmt_time_to_validate = arrow.get(spec_to_validate[\"end_ts\"]).format(\"YYYY-MM-DD\")\n",
    "if (start_fmt_time_to_validate != spec_to_validate[\"start_fmt_date\"]):\n",
    "    print(\"VALIDATION FAILED, got start %s, expected %s\" % (start_fmt_time_to_validate, spec_to_validate[\"start_fmt_date\"]))\n",
    "if (end_fmt_time_to_validate != spec_to_validate[\"end_fmt_date\"]):\n",
    "    print(\"VALIDATION FAILED, got end %s, expected %s\" % (end_fmt_time_to_validate, spec_to_validate[\"end_fmt_date\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating calibration trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_for_calibration_test(trip):\n",
    "    curr_map = folium.Map()\n",
    "    if trip[\"start_loc\"] is None or trip[\"end_loc\"] is None:\n",
    "        return curr_map\n",
    "    curr_start = lonlat_swap(trip[\"start_loc\"][\"coordinates\"])\n",
    "    curr_end = lonlat_swap(trip[\"end_loc\"][\"coordinates\"])\n",
    "    folium.Marker(curr_start, icon=folium.Icon(color=\"green\"),\n",
    "                  popup=\"Start: %s\" % trip[\"start_loc\"][\"name\"]).add_to(curr_map)\n",
    "    folium.Marker(curr_end, icon=folium.Icon(color=\"red\"),\n",
    "                  popup=\"End: %s\" % trip[\"end_loc\"][\"name\"]).add_to(curr_map)\n",
    "    folium.PolyLine([curr_start, curr_end], popup=trip[\"id\"]).add_to(curr_map)\n",
    "    curr_map.fit_bounds([curr_start, curr_end])    \n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:(0.0, 4);\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,PCFET0NUWVBFIGh0bWw+CjxoZWFkPiAgICAKICAgIDxtZXRhIGh0dHAtZXF1aXY9ImNvbnRlbnQtdHlwZSIgY29udGVudD0idGV4dC9odG1sOyBjaGFyc2V0PVVURi04IiAvPgo8L2hlYWQ+Cjxib2R5PiAgICAKPC9ib2R5Pgo8c2NyaXB0PiAgICAKPC9zY3JpcHQ+\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<branca.element.Figure at 0x7fbacc86d820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_tests = spec_to_validate[\"calibration_tests\"]\n",
    "rows = get_row_count(len(calibration_tests), 4)\n",
    "calibration_maps = bre.Figure((rows,4))\n",
    "for i, t in enumerate(calibration_tests):\n",
    "    if t[\"config\"][\"sensing_config\"] != sensing_configs[t[\"config\"][\"id\"]][\"sensing_config\"]:\n",
    "        print(\"Mismatch in config for test\" % t)\n",
    "    curr_map = get_map_for_calibration_test(t)\n",
    "    calibration_maps.add_subplot(rows, 4, i+1).add_child(curr_map)\n",
    "calibration_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating evaluation trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-4acadc3f5563>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-4acadc3f5563>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if isinstance(trip[\"waypoint_coords\"], dict)\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_map_for_travel_leg(trip):\n",
    "    curr_map = folium.Map()\n",
    "    [m.add_to(curr_map) for m in get_marker(trip[\"start_loc\"], \"green\")]\n",
    "    [m.add_to(curr_map) for m in get_marker(trip[\"end_loc\"], \"red\")]\n",
    "    # trips from relations won't have waypoints\n",
    "    if \"waypoint_coords\" in trip:\n",
    "        if isinstance(trip[\"waypoint_coords\"], dict):\n",
    "            for i, wpc in enumerate(trip[\"waypoint_coords\"][\"geometry\"][\"coordinates\"]):\n",
    "                folium.map.Marker(\n",
    "                    lonlat_swap(wpc), popup=\"%d\" % i,\n",
    "                    icon=fof.DivIcon(class_name='leaflet-div-icon')).add_to(curr_map)\n",
    "        else:\n",
    "            for wpcs in trip[\"waypoint_coords\"]:\n",
    "                for i, wpc in enumerate(wpcs[\"geometry\"][\"coordinates\"]):\n",
    "                    folium.map.Marker(\n",
    "                        lonlat_swap(wpc), popup=\"%d\" % i,\n",
    "                        icon=fof.DivIcon(class_name='leaflet-div-icon')).add_to(curr_map)\n",
    "    \n",
    "    latlng_route_coords = [[lonlat_swap(rc) for rc in coords[\"geometry\"][\"coordinates\"]] for coords in trip[\"route_coords\"]]\n",
    "    for ll in latlng_route_coords:\n",
    "        folium.PolyLine(ll, popup=\"%s: %s\" % (trip[\"mode\"], trip[\"name\"])).add_to(curr_map)\n",
    "        \n",
    "    for i, c in enumerate(latlng_route_coords):\n",
    "        folium.CircleMarker(c, radius=5, popup=\"%d: %s\" % (i, c)).add_to(curr_map)\n",
    "        \n",
    "    curr_map.fit_bounds(ful.get_bounds(trip[\"route_coords\"][0][\"geometry\"][\"coordinates\"], lonlat=True))\n",
    "    \n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_for_shim_leg(trip):\n",
    "    curr_map = folium.Map()\n",
    "    mkrs = get_marker(trip[\"loc\"], \"purple\")\n",
    "    for mkr in mkrs:\n",
    "        mkr.add_to(curr_map)\n",
    "    curr_map.fit_bounds(mkrs[0].get_bounds())\n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation_trips = spec_to_validate[\"evaluation_trips\"]\n",
    "map_list = []\n",
    "for t in evaluation_trips:\n",
    "    for l in t[\"legs\"]:\n",
    "        if l[\"type\"] == \"TRAVEL\":\n",
    "            curr_map = get_map_for_travel_leg(l)\n",
    "            map_list.append(curr_map)\n",
    "        else:\n",
    "            curr_map = get_map_for_shim_leg(l)\n",
    "            map_list.append(curr_map)\n",
    "\n",
    "rows = get_row_count(len(map_list), 2)\n",
    "evaluation_maps = bre.Figure(ratio=\"{}%\".format((rows/2) * 100))\n",
    "for i, curr_map in enumerate(map_list):\n",
    "    evaluation_maps.add_subplot(rows, 2, i+1).add_child(curr_map)\n",
    "evaluation_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating start and end polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_start_end_contains(leg):\n",
    "    points = gpd.GeoSeries([shpg.Point(p) for p in leg[\"route_coords\"][\"geometry\"][\"coordinates\"]])\n",
    "    start_loc = shpg.shape(leg[\"start_loc\"][\"geometry\"])\n",
    "    end_loc = shpg.shape(leg[\"end_loc\"][\"geometry\"])\n",
    "    start_contains = points.apply(lambda p: start_loc.contains(p))\n",
    "    print(points[start_contains])\n",
    "    end_contains = points.apply(lambda p: end_loc.contains(p))\n",
    "    print(points[end_contains])\n",
    "    # Some of the points are within the start and end polygons\n",
    "    assert start_contains.any()\n",
    "    assert end_contains.any()\n",
    "    \n",
    "    # The first and last point are within the start and end polygons\n",
    "    assert start_contains.iloc[0], points.head()\n",
    "    assert end_contains.iloc[-1], points.tail()\n",
    "    \n",
    "    # The points within the polygons are contiguous\n",
    "    max_index_diff_start = pd.Series(start_contains[start_contains == True].index).diff().max()\n",
    "    max_index_diff_end = pd.Series(end_contains[end_contains == True].index).diff().max()\n",
    "    assert pd.isnull(max_index_diff_start) or max_index_diff_start == 1, \"Max diff in index = %s for points %s\" % (gpd.GeoSeries(start_contains[end_contains == True].index).diff().max(), points.head())\n",
    "    assert pd.isnull(max_index_diff_end) or max_index_diff_end == 1, \"Max diff in index = %s for points %s\" % (gpd.GeoSeries(end_contains[end_contains == True].index).diff().max(), points.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "invalid_legs = []\n",
    "for t in evaluation_trips:\n",
    "    for l in t[\"legs\"]:\n",
    "        if l[\"type\"] == \"TRAVEL\" and l[\"id\"] not in invalid_legs:\n",
    "            print(\"Checking leg %s, %s\" % (t[\"id\"], l[\"id\"]))\n",
    "            check_start_end_contains(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating sensing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss in spec_to_validate[\"sensing_settings\"]:\n",
    "    for phoneOS, compare_map in ss.items():\n",
    "        compare_list = compare_map[\"compare\"]\n",
    "        for i, ssc in enumerate(compare_map[\"sensing_configs\"]):\n",
    "            if ssc[\"id\"] != compare_list[i]:\n",
    "                print(\"Mismatch in sensing configurations for %s\" % ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
