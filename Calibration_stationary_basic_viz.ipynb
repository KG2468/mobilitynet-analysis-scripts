{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary calibration\n",
    "\n",
    "This notebook contains the results of calibrating the 4 phones when configured next to each other with the same settings and placed next to each other in the same bookcase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and validating data\n",
    "import emeval.input.spec_details as eisd\n",
    "import emeval.input.phone_view as eipv\n",
    "import emeval.input.eval_view as eiev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers\n",
    "import emeval.viz.phone_view as ezpv\n",
    "import emeval.viz.eval_view as ezev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For maps\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and validate data\n",
    "\n",
    "The first issue to note is that we actually have two specs here. The first spec is the checked in `evaluation.spec.sample`, which defines calibration for both stationary and moving instances, and some evaluation trips. However, while starting with the calibration, we noticed some inconsistencies between the power curves. So in order to be more consistent, I defined a second, calibration-only spec `examples/calibration.only.json`, which essentially repeats the calibration experiments multiple times.\n",
    "\n",
    "After that, I returned to the first set of experiments for the moving calibration and the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASTORE_URL = \"http://cardshark.cs.berkeley.edu\"\n",
    "AUTHOR_EMAIL = \"shankari@eecs.berkeley.edu\"\n",
    "sd_hf = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"sfba_hf_calibration_stationary_only\")\n",
    "sd_mf = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"sfba_med_freq_calibration_stationary_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_hf = eipv.PhoneView(sd_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_mf = eipv.PhoneView(sd_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ezpv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validation fails because we forgot to multiply the filter_time by 1000 before setting it.\n",
    "So we set the value to 1 ms when we meant to set it to 1 sec.\n",
    "This is not a super bad issue since:\n",
    "- it only affects android\n",
    "- due to built-in throttling the data is actually returned only at 1sec frequency or even less anyway\n",
    "- we don't use this to model anything else, we just use it to help choose regimes for further testing, and for checking that the drain is consistent\n",
    "\n",
    "We had fixed this bug before the medium frequency collection (phew!) so that does validate properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pv_hf.validate()\n",
    "pv_mf.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_hf = eiev.EvaluationView()\n",
    "ev_hf.from_view_multiple_runs(pv_hf, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_mf = eiev.EvaluationView()\n",
    "ev_mf.from_view_multiple_runs(pv_mf, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize battery drain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic visualization\n",
    "\n",
    "Dump everything into one giant graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ifig, [android_ax, ios_ax]) = plt.subplots(ncols=1, nrows=2, figsize=(10,10))\n",
    "\n",
    "ezpv.plot_all_power_drain(ios_ax, pv_hf.map()[\"ios\"], \"calibration\", \"stationary\")\n",
    "ezpv.plot_all_power_drain(ios_ax, pv_mf.map()[\"ios\"], \"calibration\", \"stationary\")\n",
    "ios_ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), ncol=2)\n",
    "ezpv.plot_all_power_drain(android_ax, pv_hf.map()[\"android\"], \"calibration\", \"stationary\")\n",
    "ezpv.plot_all_power_drain(android_ax, pv_mf.map()[\"android\"], \"calibration\", \"stationary\")\n",
    "android_ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ezpv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped by sensing configuration\n",
    "\n",
    "If the previous graph is too busy, this graph groups the values from similar experiments together so that we can see whether they separate out or not. We can clearly see two clusters of lines for both android and iOS.\n",
    "\n",
    "- For android, high accuracy high frequency sensing is distinct, and lowering either the frequency (e.g. `best_high_accuracy_medium_freq_stationary` or the accuracy `100m_balanced_accuracy_medium_freq_stationary`) moves to the other cluster \n",
    "- For iOS, the the frequency does not seem to make any difference. The only variation is caused by lowering the accuracy to 100m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ifig, [android_ax, ios_ax]) = plt.subplots(ncols=1, nrows=2, figsize=(10,10))\n",
    "\n",
    "color_map = {}\n",
    "legend_map = {}\n",
    "\n",
    "(color_map, legend_map) = ezpv.plot_collapsed_all_power_drain(ios_ax, pv_hf.map()[\"ios\"], \"calibration\", \"stationary\", color_map, legend_map)\n",
    "(color_map, legend_map) = ezpv.plot_collapsed_all_power_drain(ios_ax, pv_mf.map()[\"ios\"], \"calibration\", \"stationary\", color_map, legend_map)\n",
    "(color_map, legend_map) = ezpv.plot_collapsed_all_power_drain(android_ax, pv_hf.map()[\"android\"], \"calibration\", \"stationary\", color_map, legend_map)\n",
    "(color_map, legend_map) = ezpv.plot_collapsed_all_power_drain(android_ax, pv_mf.map()[\"android\"], \"calibration\", \"stationary\", color_map, legend_map)\n",
    "ios_ax.legend(legend_map.values(), legend_map.keys())\n",
    "android_ax.legend(legend_map.values(), legend_map.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate plots to see individual variations\n",
    "\n",
    "In case we want to see individual variations in a less overwhelming way, we can plot the individual runs in separate plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phone based plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ifig, ax) = plt.subplots(figsize=(12,3), nrows=0, ncols=0)\n",
    "ezpv.plot_separate_power_drain(ifig, pv_hf.map()[\"ios\"], 4, \"calibration\", \"stationary\")\n",
    "ezpv.plot_separate_power_drain(ifig, pv_mf.map()[\"ios\"], 4, \"calibration\", \"stationary\")\n",
    "(ifig, ax) = plt.subplots(figsize=(12,3), nrows=0, ncols=0)\n",
    "ezpv.plot_separate_power_drain(ifig, pv_hf.map()[\"android\"], 4, \"calibration\", \"stationary\")\n",
    "ezpv.plot_separate_power_drain(ifig, pv_mf.map()[\"android\"], 4, \"calibration\", \"stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment based plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ifig, ax) = plt.subplots(figsize=(12,3), nrows=0, ncols=0)\n",
    "ezev.plot_separate_power_drain_multiple_runs(ifig, 3, ev_hf.map(\"calibration\")[\"ios\"], \"\")\n",
    "(ifig, ax) = plt.subplots(figsize=(12,3), nrows=0, ncols=0)\n",
    "ezev.plot_separate_power_drain_multiple_runs(ifig, 3, ev_hf.map(\"calibration\")[\"android\"], \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking counts\n",
    "\n",
    "We now check the number of data points collected during calibration and their distribution in an effort to validate the duty cycling. Observations from this are:\n",
    "\n",
    "##### on android: more points = more power drain\n",
    "\n",
    "As we would expect, the number of points across the various phones and the various runs is almost identical. In the cases where it is significantly different (e.g. `high-accuracy-stationary-0` on `ucb-sdb-android-1` and `high-accuracy-stationary-3` on `ucb-sdb-android-3`), we have see significant differences in the power drain as well. However, we do not understand why these two runs behave differently from the other runs.\n",
    "\n",
    "##### on iOS: almost no points\n",
    "\n",
    "Since iOS has a distance filter, and not a time filter, and this calibration was stationary, almost no points are generated for high accuracy sensing. However, with the 100m sensing, we do get a significant number of points (an order of magnitude more), although nowhere near the number of entries on android.\n",
    "\n",
    "##### on android: medium accuracy = almost no points\n",
    "\n",
    "On android, medium accuracy sensing generates two orders of magnitude fewer points than high accuracy. So the additional power drain on android probably reflects not just the sensing cost but also the processing cost. This also indicates that the medium accuracy sensing, which relies on WiFi and cellular signal strengths, is likely to be suspended when the phone is in doze mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_count_df = ezpv.get_count_df(pv_hf); hf_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_count_df = ezpv.get_count_df(pv_mf); mf_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ifig, ax) = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "hf_count_df.filter(like=\"best_high_accuracy\").filter(like=\"android\", axis=0).plot(ax=ax[0],kind=\"bar\")\n",
    "hf_count_df.filter(like=\"ios\", axis=0).plot(ax=ax[1],kind=\"bar\")\n",
    "hf_count_df.filter(like=\"ten_meter_balanced\").filter(like=\"android\", axis=0).plot(ax=ax[2],kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ifig, ax) = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "mf_count_df.filter(like=\"best_high_accuracy\").filter(like=\"android\", axis=0).plot(ax=ax[0],kind=\"bar\")\n",
    "mf_count_df.filter(like=\"ios\", axis=0).plot(ax=ax[1],kind=\"bar\")\n",
    "mf_count_df.filter(like=\"100m_balanced\").filter(like=\"android\", axis=0).plot(ax=ax[2],kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
