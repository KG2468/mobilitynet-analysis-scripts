{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate evaluation of phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook retrieves the evaluation results for a particular experiment and validates them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to run experiments, you only need to edit these variables. The notebook will retrieve the appropriate spec, use it to find the evaluation periods from the database and validate the evaluation. You probably want to publish this notebook along with your results so that others can examine it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASTORE_URL = \"http://cardshark.cs.berkeley.edu\"\n",
    "AUTHOR_EMAIL = \"shankari@eecs.berkeley.edu\" # e.g. shankari@eecs.berkeley.edu\n",
    "CURR_SPEC_ID = \"many_unimodal_trips_sb\" # e.g. sfba_calibration_only_1\n",
    "MAX_DURATION_VARIATION = 5 * 60 # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import arrow\n",
    "import pandas as pd\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.features as fof\n",
    "import folium.plugins as fpl\n",
    "import folium.utilities as ful\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some simple utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_count(n_maps, cols):\n",
    "    rows = int(n_maps / cols)\n",
    "    if (n_maps % cols != 0):\n",
    "        rows = rows + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the ability to make calls to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_from_server(user_label, key_list, start_ts, end_ts):\n",
    "    post_msg = {\n",
    "        \"user\": user_label,\n",
    "        \"key_list\": key_list,\n",
    "        \"start_time\": start_ts,\n",
    "        \"end_time\": end_ts\n",
    "    }\n",
    "    # print(\"About to retrieve messages using %s\" % post_msg)\n",
    "    response = requests.post(DATASTORE_URL+\"/datastreams/find_entries/timestamp\", json=post_msg)\n",
    "    # print(\"response = %s\" % response)\n",
    "    response.raise_for_status()\n",
    "    ret_list = response.json()[\"phone_data\"]\n",
    "    # print(\"Found %d entries\" % len(ret_list))\n",
    "    return ret_list\n",
    "\n",
    "def retrieve_all_data_from_server(user_label, key_list):\n",
    "    return retrieve_data_from_server(user_label, key_list, 0, arrow.get().timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the current spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spec_entry_list = retrieve_all_data_from_server(AUTHOR_EMAIL, [\"config/evaluation_spec\"])\n",
    "curr_spec_entry = None\n",
    "for s in all_spec_entry_list:\n",
    "    if s[\"data\"][\"label\"][\"id\"] == CURR_SPEC_ID:\n",
    "        curr_spec_entry = s\n",
    "curr_spec_wrapper = curr_spec_entry[\"data\"]\n",
    "curr_spec = curr_spec_wrapper[\"label\"]\n",
    "curr_spec[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all evaluation transitions within the start and end times of this spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_start_ts = curr_spec_wrapper[\"start_ts\"]\n",
    "eval_end_ts = curr_spec_wrapper[\"end_ts\"] + 7 * 24 * 60 * 60 # 7 days\n",
    "eval_tz = curr_spec[\"region\"][\"timezone\"]\n",
    "print(\"Evaluation ran from %s -> %s\" % (arrow.get(eval_start_ts).to(eval_tz), arrow.get(eval_end_ts).to(eval_tz)))\n",
    "phone_labels = curr_spec[\"phones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data model here is:\n",
    "\n",
    "```\n",
    "eval_transitions\n",
    "    - android\n",
    "        - ucb.sdb.android.1\n",
    "            - list of evaluation transitions\n",
    "        - ....\n",
    "    - ios\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_transitions = copy.deepcopy(phone_labels)\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Reading data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        print(\"Loading transitions for phone %s\" % phone_label)\n",
    "        curr_phone_transitions = retrieve_data_from_server(phone_label, [\"manual/evaluation_transition\"], eval_start_ts, eval_end_ts)\n",
    "        curr_phone_role = phone_map[phone_label]\n",
    "        phone_map[phone_label] = {\"role\": curr_phone_role}\n",
    "        phone_map[phone_label][\"transitions\"] = curr_phone_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find evaluation transitions, validate and map them to ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here onwards, we will add the results of manipulation to each phone entry - e.g.\n",
    "\n",
    "```\n",
    "eval_transitions\n",
    "    - android\n",
    "        - ucb.sdb.android.1\n",
    "            - transitions (all transition entries, added in previous step)\n",
    "            - evaluation_transitions (evaluation transitions, will be added in this step)\n",
    "        - ....\n",
    "    - ios\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imported to emeval/input/phone_view.py\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        print(\"Processing transitions for phone %s\" % phone_label)\n",
    "        curr_phone_transitions = [t[\"data\"] for t in phone_map[phone_label][\"transitions\"]]\n",
    "        # print(curr_phone_transitions)\n",
    "        curr_evaluation_transitions = [t for t in curr_phone_transitions if (t[\"transition\"] in [\"START_EVALUATION_PERIOD\", \"STOP_EVALUATION_PERIOD\", 2, 3])]\n",
    "        print(\"Filtered %d total -> %d evaluation transitions \" % (len(curr_phone_transitions), len(curr_evaluation_transitions)))\n",
    "        phone_map[phone_label][\"evaluation_transitions\"] = curr_evaluation_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_1_transitions = eval_transitions[\"android\"][\"ucb-sdb-android-2\"][\"evaluation_transitions\"]\n",
    "print(\"\\n\".join([str((t[\"transition\"], t[\"trip_id\"], t[\"ts\"], arrow.get(t[\"ts\"]).to(eval_tz))) for t in ios_1_transitions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_1_transitions = eval_transitions[\"ios\"][\"ucb-sdb-ios-3\"][\"evaluation_transitions\"]\n",
    "print(\"\\n\".join([str((t[\"transition\"], t[\"trip_id\"], t[\"ts\"], arrow.get(t[\"ts\"]).to(eval_tz))) for t in ios_1_transitions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect that transitions occur in pairs\n",
    "def transitions_to_ranges(transition_list, start_tt, end_tt, start_ti, end_ti):\n",
    "    start_transitions = transition_list[::2]\n",
    "    end_transitions = transition_list[1::2]\n",
    "    if len(transition_list) % 2 == 0:\n",
    "        print(\"All evaluation is complete, nothing to change\")\n",
    "    else:\n",
    "        print(\"Ongoing evaluation, adding fake end transition\")\n",
    "        last_start_transition = phone_map[phone_label][\"transitions\"][-1]\n",
    "        fake_end_transition = copy.copy(last_start_transition)\n",
    "        fake_end_transition[\"data\"][\"transition\"] = end_tt\n",
    "        curr_ts = arrow.get().timestamp\n",
    "        fake_end_transition[\"data\"][\"ts\"] = curr_ts\n",
    "        if \"fmt_time\" in last_start_transition[\"data\"]:\n",
    "            fake_end_transition[\"data\"][\"fmt_time\"] = arrow.get(curr_ts).to(eval_tz)\n",
    "        fake_end_transition[\"metadata\"][\"write_ts\"] = curr_ts\n",
    "        if \"write_fmt_time\" in last_start_transition[\"metadata\"]:\n",
    "            fake_end_transition[\"metadata\"][\"write_fmt_time\"] = arrow.get(curr_ts).to(eval_tz)\n",
    "        fake_end_transition[\"metadata\"][\"platform\"] = \"fake\"\n",
    "        if \"local_dt\" in fake_end_transition[\"data\"]:\n",
    "            del fake_end_transition[\"data\"][\"local_dt\"]\n",
    "\n",
    "    range_list = []\n",
    "    for (s, e) in zip(start_transitions, end_transitions):\n",
    "        # print(\"------------------------------------- \\n %s -> \\n %s\" % (s, e))\n",
    "        assert s[\"transition\"] == start_tt or s[\"transition\"] == start_ti, \"Start transition has %s transition\" % s[\"transition\"]\n",
    "        assert e[\"transition\"] == end_tt or s[\"transition\"] == end_ti, \"Stop transition has %s transition\" % s[\"transition\"]\n",
    "        assert s[\"trip_id\"] == e[\"trip_id\"], \"trip_id mismatch! %s != %s\" % (s[\"trip_id\"], e[\"trip_id\"])\n",
    "        assert e[\"ts\"] > s[\"ts\"], \"end %s is before start %s\" % (arrow.get(e[\"ts\"]), arrow.get(s[\"ts\"]))\n",
    "        for f in [\"spec_id\", \"device_manufacturer\", \"device_model\", \"device_version\"]:\n",
    "            assert s[f] == e[f], \"Field %s mismatch! %s != %s\" % (f, s[f], e[f])\n",
    "        curr_range = {\"trip_id\": s[\"trip_id\"], \"start_ts\": s[\"ts\"], \"end_ts\": e[\"ts\"], \"duration\": (e[\"ts\"] - s[\"ts\"])}\n",
    "        range_list.append(curr_range)\n",
    "        \n",
    "    return range_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_to_ranges(eval_transitions[\"ios\"][\"ucb-sdb-ios-1\"][\"evaluation_transitions\"], \"START_EVALUATION_PERIOD\", \"STOP_EVALUATION_PERIOD\", 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_evaluation_ranges = transitions_to_ranges(phone_map[phone_label][\"evaluation_transitions\"], \"START_EVALUATION_PERIOD\", \"STOP_EVALUATION_PERIOD\", 2, 3)\n",
    "        print(\"Found %d ranges for phone %s\" % (len(curr_evaluation_ranges), phone_label))\n",
    "        phone_map[phone_label][\"evaluation_ranges\"] = curr_evaluation_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the ranges for individual phones\n",
    "\n",
    "This involves two main checks:\n",
    "- that we have at least one evaluation range for each test in the spec. Note that we do not currently enforce that we have exactly one evaluation range for each test, on the theory that more evaluation is always good. But I am open to argument about this\n",
    "- that the settings in the evaluation range are consistent with the spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_config_map = {\n",
    "    \"fixed:ACCURACY_CONTROL\": {\n",
    "        \"is_duty_cycling\": False,\n",
    "        \"accuracy\": [\"PRIORITY_HIGH_ACCURACY\",\"kCLLocationAccuracyBest\"],\n",
    "        \"filter\": 1,\n",
    "    },\n",
    "    \"fixed:POWER_CONTROL\": {\n",
    "        \"is_duty_cycling\": False,\n",
    "        \"accuracy\": [\"PRIORITY_NO_POWER\",\"kCLLocationAccuracyThreeKilometers\"],\n",
    "        \"filter\": 1200,\n",
    "    }\n",
    "}\n",
    "for ct in curr_spec[\"sensing_settings\"]:\n",
    "    for s in ct[\"sensing_configs\"]:\n",
    "        expected_config_map[\"%s:%s\" % (ct[\"name\"], s[\"id\"])] = s[\"sensing_config\"]\n",
    "# print(expected_config_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current accuracy constants\n",
    "# Since we can't read these from the phone, we hardcoded them from the documentation\n",
    "# If there are validation failures, these need to be updated\n",
    "# In the future, we could upload the options from the phone (maybe the accuracy control)\n",
    "# but that seems like overkill here\n",
    "\n",
    "accuracy_options = {\n",
    "    \"android\": {\n",
    "        \"PRIORITY_HIGH_ACCURACY\": 100,\n",
    "        \"PRIORITY_BALANCED_POWER_ACCURACY\": 102,\n",
    "        \"PRIORITY_LOW_POWER\": 104,\n",
    "        \"PRIORITY_NO_POWER\": 105\n",
    "    },\n",
    "    \"ios\": {\n",
    "        \"kCLLocationAccuracyBestForNavigation\": -2,\n",
    "        \"kCLLocationAccuracyBest\": -1,\n",
    "        \"kCLLocationAccuracyNearestTenMeters\": 10,\n",
    "        \"kCLLocationAccuracyHundredMeters\": 100,\n",
    "        \"kCLLocationAccuracyKilometer\": 1000,\n",
    "        \"kCLLocationAccuracyThreeKilometers\": 3000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_array_idx = lambda phoneOS: 0 if phoneOS == \"android\" else 1\n",
    "\n",
    "def validate_filter(phoneOS, config_during_test, expected_config):\n",
    "    # filter checking is a bit tricky because the expected value has two possible values and the real config has two possible values\n",
    "    expected_filter = expected_config[\"filter\"]\n",
    "    if type(expected_filter) == int:\n",
    "        ev = expected_filter\n",
    "    else:\n",
    "        assert type(expected_filter) == list, \"platform specific filters should be specified in array, not %s\" % expected_filter\n",
    "        ev = expected_filter[opt_array_idx(phoneOS)]\n",
    "        \n",
    "    if phoneOS == \"android\":\n",
    "        cvf = \"filter_time\"\n",
    "    elif phoneOS == \"ios\":\n",
    "        cvf = \"filter_distance\"\n",
    "        \n",
    "    assert config_during_test[cvf] == ev, \"Field filter mismatch! %s != %s\" % (config_during_test, expected_config)\n",
    "    \n",
    "def validate_accuracy(phoneOS, config_during_test, expected_config):\n",
    "    # expected config accuracy is an array of strings [\"PRIORITY_BALANCED_POWER_ACCURACY\", \"kCLLocationAccuracyNearestTenMeters\"]\n",
    "    # so we find the string at the correct index and then map it to the value from the options\n",
    "    ev = accuracy_options[phoneOS][expected_config[\"accuracy\"][opt_array_idx(phoneOS)]]\n",
    "    assert config_during_test[\"accuracy\"] == ev, \"Field accuracy mismatch! %s != %s\" % (config_during_test[accuracy], ev)\n",
    "\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    # print(\"Processing data for %s phones, next level keys = %s\" % (phoneOS, phone_map.keys()))\n",
    "    for phone_label in phone_map:\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        unique_test_ids = set(filter(lambda id: id != \"fixed\", [r[\"trip_id\"].split(\":\")[0] for r in curr_evaluation_ranges]))\n",
    "        # This is a tricky check since, unlike in the calibration case, we will have different ids for the different evaluation\n",
    "        # ranges. For now, let us just assert that the evaluation range is valid\n",
    "        # print(\"Unique test ids = %s\" % unique_test_ids)\n",
    "        spec_test_ids = set([ct[\"name\"] for ct in curr_spec[\"sensing_settings\"]])\n",
    "        # print(spec_test_ids)\n",
    "        # <= represents subset for set objects\n",
    "        assert unique_test_ids <= spec_test_ids, \"Invalid evaluation test while comparing %s, %s\" % (unique_test_ids, spec_test_ids)\n",
    "        for r in curr_evaluation_ranges:\n",
    "            config_during_test_entries = retrieve_data_from_server(phone_label, [\"config/sensor_config\"], r[\"start_ts\"], r[\"end_ts\"])\n",
    "            print(\"%s -> %s\" % (r[\"trip_id\"], [c[\"data\"][\"accuracy\"] for c in config_during_test_entries]))\n",
    "            # assert len(config_during_test_entries) == 1, \"Out of band configuration? Found %d config changes\" % len(config_during_test_entries)\n",
    "            config_during_test = config_during_test_entries[0][\"data\"]\n",
    "            expected_config = expected_config_map[r[\"trip_id\"]]\n",
    "            # print(config_during_test.keys(), expected_config.keys())\n",
    "            validate_filter(phoneOS, config_during_test, expected_config)\n",
    "            validate_accuracy(phoneOS, config_during_test, expected_config)\n",
    "            for f in expected_config:\n",
    "                if f != \"accuracy\" and f != \"filter\":\n",
    "                    assert config_during_test[f] == expected_config[f], \"Field %s mismatch! %s != %s\" % (f, config_during_test[f], expected_config[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link evaluation ranges to each other\n",
    "\n",
    "Since the evaluation ranges have separate IDs, it is hard to link them the way we link the calibration ranges.\n",
    "So let's add a common field (`eval_common_trip_id`) to each of the matching ranges for easy checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_common_eval_ranges():\n",
    "    for phoneOS, phone_map in eval_transitions.items(): # android, ios\n",
    "        print(\"Processing data for %s phones\" % phoneOS)\n",
    "        all_eval_ranges = [m[\"evaluation_ranges\"] for m in phone_map.values()]\n",
    "        # all the lengths are equal - i.e. the set of lengths has one entr\n",
    "        assert len(set([len(a) for a in all_eval_ranges])) == 1\n",
    "        for ctuple in zip(*all_eval_ranges):\n",
    "            eval_cols = ctuple[1:-1]\n",
    "            # print([ct[\"trip_id\"] for ct in ctuple], [ct[\"trip_id\"] for ct in eval_cols])\n",
    "            get_common_name = lambda r: r[\"trip_id\"].split(\":\")[0]\n",
    "            get_separate_role = lambda r: r[\"trip_id\"].split(\":\")[1]\n",
    "            common_names = set([get_common_name(r) for r in eval_cols])\n",
    "            separate_roles = [get_separate_role(r) for r in eval_cols]\n",
    "            # print(separate_roles)\n",
    "            assert len(common_names) == 1\n",
    "            common_name = list(common_names)[0]\n",
    "            # print(common_name)\n",
    "            for r in ctuple:\n",
    "                r[\"eval_common_trip_id\"] = common_name\n",
    "            ctuple[0][\"eval_role\"] = \"accuracy_control\"\n",
    "            for r, sr in zip(eval_cols, separate_roles):\n",
    "                r[\"eval_role\"] = sr\n",
    "            ctuple[-1][\"eval_role\"] = \"power_control\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_common_eval_ranges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_transitions[\"android\"][\"ucb-sdb-android-1\"][\"evaluation_ranges\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and validate trips\n",
    "\n",
    "for each evaluation range, we have multiple possible trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_labels[\"android\"][\"ucb-sdb-android-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_control_maps = {}\n",
    "power_control_maps = {}\n",
    "eval_phone_maps = {}\n",
    "\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    eval_phone_maps[phoneOS] = {}\n",
    "    for phone_label in phone_map:\n",
    "        curr_role = phone_map[phone_label][\"role\"]\n",
    "        if curr_role == \"accuracy_control\":\n",
    "            accuracy_control_maps[phoneOS] = phone_map[phone_label]\n",
    "        elif curr_role == \"power_control\":\n",
    "            power_control_maps[phoneOS] = phone_map[phone_label]\n",
    "        else:\n",
    "            assert curr_role.startswith(\"evaluation\")\n",
    "            eval_phone_maps[phoneOS][phone_label] = phone_map[phone_label]\n",
    "\n",
    "print(len(accuracy_control_maps), len(power_control_maps), len(eval_phone_maps))\n",
    "print(accuracy_control_maps.keys(), power_control_maps.keys(), eval_phone_maps.keys())\n",
    "print(eval_phone_maps[\"android\"].keys(), eval_phone_maps[\"ios\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the control trip ranges\n",
    "# Note that for the control phones, these are not split by evaluation range since there are no evaluation ranges for the controls\n",
    "for phoneOS, phone_map in accuracy_control_maps.items():\n",
    "    curr_control_transitions = [t[\"data\"] for t in phone_map[\"transitions\"]] # from control phone\n",
    "    curr_evaluation_ranges = phone_map[\"evaluation_ranges\"] # from this phone\n",
    "    trip_type_check = lambda t: t[\"transition\"] in [\"START_EVALUATION_TRIP\", \"STOP_EVALUATION_TRIP\", 4, 5]\n",
    "    trip_time_check = lambda t, r: t[\"ts\"] >= r[\"start_ts\"] and t[\"ts\"] <= r[\"end_ts\"]\n",
    "    for i, r in enumerate(curr_evaluation_ranges):\n",
    "        # We have to get the evaluation details from one of the evaluation phones\n",
    "        curr_eval_trips_transitions = [t for t in curr_control_transitions if trip_type_check(t) and trip_time_check(t, r)]\n",
    "        # print(\"\\n\".join([str((t[\"transition\"], t[\"trip_id\"], t[\"ts\"], arrow.get(t[\"ts\"]).to(eval_tz))) for t in curr_eval_trips_transitions]))\n",
    "        # print(len(curr_eval_trips_transitions))\n",
    "        curr_eval_trips_ranges = transitions_to_ranges(curr_eval_trips_transitions, \"START_EVALUATION_TRIP\", \"STOP_EVALUATION_TRIP\", 4, 5)\n",
    "        print(\"%s: Found %s trips for evaluation %s\" % (phoneOS, len(curr_eval_trips_ranges), r[\"trip_id\"]))\n",
    "        # print(curr_eval_trips_ranges)\n",
    "        print(\"\\n\".join([str((tr[\"trip_id\"], tr[\"duration\"], arrow.get(tr[\"start_ts\"]).to(eval_tz), arrow.get(tr[\"end_ts\"]).to(eval_tz))) for tr in curr_eval_trips_ranges]))\n",
    "        r[\"evaluation_trip_ranges\"] = curr_eval_trips_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the ranges to the power control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS in accuracy_control_maps.keys():\n",
    "    matching_accuracy_control_map = accuracy_control_maps[phoneOS]\n",
    "    matching_power_control_map = power_control_maps[phoneOS]\n",
    "    print(matching_power_control_map.keys())\n",
    "    curr_power_evaluation_ranges = matching_power_control_map[\"evaluation_ranges\"]\n",
    "    curr_accuracy_evaluation_ranges = matching_accuracy_control_map[\"evaluation_ranges\"]\n",
    "    assert len(curr_power_evaluation_ranges) == len(curr_accuracy_evaluation_ranges)\n",
    "    for i, (rp, ra) in enumerate(zip(curr_power_evaluation_ranges, curr_accuracy_evaluation_ranges)):\n",
    "        accuracy_eval_trips_ranges = ra[\"evaluation_trip_ranges\"] # from this phone\n",
    "        print(\"%s: Copying %s accuracy trips to power, before = %s\" % (phoneOS, len(accuracy_eval_trips_ranges),\n",
    "            len(rp[\"evaluation_trip_ranges\"]) if \"evaluation_trip_ranges\" in rp else 0))\n",
    "        rp[\"evaluation_trip_ranges\"] = copy.deepcopy(accuracy_eval_trips_ranges)\n",
    "        # print(curr_eval_trips_ranges)\n",
    "        print(\"\\n\".join([str((tr[\"trip_id\"], tr[\"duration\"], arrow.get(tr[\"start_ts\"]).to(eval_tz), arrow.get(tr[\"end_ts\"]).to(eval_tz))) for tr in curr_eval_trips_ranges]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the ranges to the evaluation maps\n",
    "\n",
    "Similar to the power control, but there are potentially `n` of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone_map has keys like \n",
    "for phoneOS in accuracy_control_maps.keys():\n",
    "    matching_accuracy_control_map = accuracy_control_maps[phoneOS]\n",
    "    matching_eval_phone_maps = eval_phone_maps[phoneOS]\n",
    "    print(matching_eval_phone_maps.keys())\n",
    "    for phone_label, phone_map in matching_eval_phone_maps.items():\n",
    "        curr_eval_evaluation_ranges = phone_map[\"evaluation_ranges\"]\n",
    "        curr_accuracy_evaluation_ranges = matching_accuracy_control_map[\"evaluation_ranges\"]\n",
    "        assert len(curr_eval_evaluation_ranges) == len(curr_accuracy_evaluation_ranges)\n",
    "        for i, (re, ra) in enumerate(zip(curr_eval_evaluation_ranges, curr_accuracy_evaluation_ranges)):\n",
    "            accuracy_eval_trips_ranges = ra[\"evaluation_trip_ranges\"] # from this phone\n",
    "            print(\"%s: Copying %s accuracy trips to %s, before = %s\" % (phoneOS, phone_label, len(accuracy_eval_trips_ranges),\n",
    "                len(re[\"evaluation_trip_ranges\"]) if \"evaluation_trip_ranges\" in re else 0))\n",
    "            re[\"evaluation_trip_ranges\"] = copy.deepcopy(accuracy_eval_trips_ranges)\n",
    "            # print(curr_eval_trips_ranges)\n",
    "            print(\"\\n\".join([str((tr[\"trip_id\"], tr[\"duration\"], arrow.get(tr[\"start_ts\"]).to(eval_tz), arrow.get(tr[\"end_ts\"]).to(eval_tz))) for tr in curr_eval_trips_ranges]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate ranges across phones\n",
    "\n",
    "This effectively has one test right now - is the duration of the tests across phones consistent?\n",
    "TODO: We should add a reasonable fuzz factor based on real evaluation.\n",
    "\n",
    "We are going to create a pandas dataframe with the following structure\n",
    "\n",
    "```\n",
    "                    android_<phone_1> android_<phone_2> android_<phone_3> ....\n",
    "<trip_id_1>\n",
    "<trip_id_2>\n",
    "...\n",
    "```\n",
    "\n",
    "Then, we can transpose it to get\n",
    "\n",
    "```\n",
    "                    <trip_id_1> <trip_id_2> <trip_id_3> ....\n",
    "android_<phone_1>\n",
    "android_<phone_2>\n",
    "...\n",
    "```\n",
    "\n",
    "then, we can get a series of durations for each `trip_id` as a series and compare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_map = {}\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_phone_duration_map = {}\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            duration_map[phone_label] = r[\"duration\"]\n",
    "#        duration_map[phoneOS+\"_\"+phone_label] = curr_phone_duration_map\n",
    "print(duration_map)\n",
    "        \n",
    "duration_series = pd.Series(duration_map)\n",
    "duration_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these are not statistical samples, the regular standard deviation/variation don't have much meaning. The variation is really caused by human control of the evaluation start/stop and the durations should be within a few minutes of each other. The expected variation defined in `MAX_DURATION_VARIATION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_variation = duration_series - duration_series.median()\n",
    "print(\"duration_variation = %s\" % (duration_variation.tolist()))\n",
    "assert duration_variation.abs().max() < MAX_DURATION_VARIATION,\\\n",
    "    \"INVALID: for %s, duration_variation.abs().max() %d > threshold %d\" % (col, duration_variation.abs().max(), MAX_DURATION_VARIATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_map = {}\n",
    "for phoneOS, phone_map in eval_phone_maps.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            curr_phone_duration_map = {}\n",
    "            for et in r[\"evaluation_trip_ranges\"]:\n",
    "                curr_phone_duration_map[et[\"trip_id\"]] = et[\"duration\"]\n",
    "            duration_map[phoneOS+\"_\"+r[\"trip_id\"]] = curr_phone_duration_map\n",
    "        \n",
    "duration_df = pd.DataFrame(duration_map).transpose()\n",
    "duration_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can evaluate the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Battery drain over time (overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in the format\n",
    "\n",
    "```\n",
    "android:\n",
    "    - <phone_1>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "    - <phone_2>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "...\n",
    "ios:\n",
    "    - <phone_1>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "    - <phone_2>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            battery_entries = retrieve_data_from_server(phone_label, [\"background/battery\"], r[\"start_ts\"], r[\"end_ts\"])\n",
    "            # ios entries before running the pipeline are marked with battery_level_ratio, which is a float from 0 ->1\n",
    "            # convert it to % to be consistent with android and easier to understand\n",
    "            if phoneOS == \"ios\":\n",
    "                for e in battery_entries:\n",
    "                    if \"battery_level_pct\" not in e[\"data\"]:\n",
    "                        e[\"data\"][\"battery_level_pct\"] = e[\"data\"][\"battery_level_ratio\"] * 100\n",
    "                        del e[\"data\"][\"battery_level_ratio\"]\n",
    "            battery_df = pd.DataFrame([e[\"data\"] for e in battery_entries])\n",
    "            battery_df[\"hr\"] = (battery_df.ts-r[\"start_ts\"])/3600.0\n",
    "            r[\"battery_df\"] = battery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_battery_df = eval_transitions[\"android\"][\"ucb-sdb-android-3\"][\"evaluation_ranges\"][0][\"battery_df\"]; test_battery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_battery_df = eval_transitions[\"android\"][\"ucb-sdb-android-4\"][\"evaluation_ranges\"][0][\"battery_df\"]; test_battery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_curves(ax, phone_map):\n",
    "    for phone_label in phone_map:\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            battery_df = r[\"battery_df\"]\n",
    "            ret_axes = battery_df.plot(x=\"hr\", y=\"battery_level_pct\", ax=ax, label=phone_label+\"_\"+r[\"trip_id\"], ylim=(0,100), sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ifig, [android_ax, ios_ax]) = plt.subplots(ncols=1, nrows=2, figsize=(25,25))\n",
    "\n",
    "plot_evaluation_curves(ios_ax, eval_transitions[\"ios\"])\n",
    "ios_ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plot_evaluation_curves(android_ax, eval_transitions[\"android\"])\n",
    "android_ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate_evaluation_curves(fig, nRows, phone_map):\n",
    "    for i, phone_label in enumerate(phone_map.keys()):\n",
    "        ax = fig.add_subplot(nRows, 2, i+1, title=phone_label)\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            battery_df = r[\"battery_df\"]\n",
    "            # print(battery_df.battery_level_pct.tolist())\n",
    "            battery_df.plot(x=\"hr\", y=\"battery_level_pct\", ax=ax, label=r[\"trip_id\"], ylim=(0,100), sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ifig, ax) = plt.subplots(figsize=(16,16))\n",
    "# nRows = get_row_count(len(eval_transitions[\"ios\"].keys()), 2)\n",
    "# print(nRows)\n",
    "# plot_separate_evaluation_curves(ifig, nRows, eval_transitions[\"android\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ifig, ax) = plt.subplots(nrows=0, ncols=0, figsize=(16,16))\n",
    "# nRows = get_row_count(len(eval_transitions[\"android\"].keys()), 2)\n",
    "# plot_separate_evaluation_curves(ifig, nRows, eval_transitions[\"ios\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location points over time (overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we download the location points and check to see that the density is largely consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            all_done = False\n",
    "            location_entries = []\n",
    "            curr_start_ts = r[\"start_ts\"]\n",
    "            prev_retrieved_count = 0\n",
    "\n",
    "            while not all_done:\n",
    "                print(\"About to retrieve data for %s from %s -> %s\" % (phone_label, curr_start_ts, r[\"end_ts\"]))\n",
    "                curr_location_entries = retrieve_data_from_server(phone_label, [\"background/location\"], curr_start_ts, r[\"end_ts\"])\n",
    "                print(\"Retrieved %d entries with timestamps %s...\" % (len(curr_location_entries), [cle[\"data\"][\"ts\"] for cle in curr_location_entries[0:10]]))\n",
    "                if len(curr_location_entries) == 0 or len(curr_location_entries) == 1 or len(curr_location_entries) == prev_retrieved_count:\n",
    "                    all_done = True\n",
    "                else:\n",
    "                    location_entries.extend(curr_location_entries)\n",
    "                    curr_start_ts = curr_location_entries[-1][\"data\"][\"ts\"]\n",
    "                    prev_retrieved_count = len(curr_location_entries)\n",
    "            location_df = pd.DataFrame([e[\"data\"] for e in location_entries])\n",
    "            location_df[\"hr\"] = (location_df.ts-r[\"start_ts\"])/3600.0\n",
    "            r[\"location_df\"] = location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_map = {}\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_phone_count_map = {}\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            curr_phone_count_map[r[\"trip_id\"]] = len(r[\"location_df\"])\n",
    "        count_map[phoneOS+\"_\"+phone_label] = curr_phone_count_map\n",
    "        \n",
    "count_df = pd.DataFrame(count_map).transpose()\n",
    "count_df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df.plot(kind=\"bar\", figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_density_df(phone_map):\n",
    "    density_map = {}\n",
    "    for phone_label in phone_map:\n",
    "        curr_phone_density_map = {}\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            density_map[phone_label+\"_\"+r[\"trip_id\"]] = r[\"location_df\"].hr\n",
    "        \n",
    "    density_df = pd.DataFrame(density_map)\n",
    "    return density_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "android_density_df = get_location_density_df(eval_transitions[\"android\"])\n",
    "nRows = get_row_count(len(android_density_df), 2)\n",
    "print(nRows)\n",
    "android_density_df.plot(kind='density', subplots=False, layout=(nRows, 2), figsize=(10,10), sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate_density_curves(fig, nRows, phone_map):\n",
    "    for i, phone_label in enumerate(phone_map.keys()):\n",
    "        ax = fig.add_subplot(nRows, 2, i+1, title=phone_label)\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            location_df = r[\"location_df\"]\n",
    "            # print(battery_df.battery_level_pct.tolist())\n",
    "            location_df.hr.plot(kind='density', ax=ax, label=r[\"trip_id\"], sharex=True, sharey=True)\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (ifig, ax) = plt.subplots(nrows=0, ncols=0, figsize=(16,16))\n",
    "# nRows = get_row_count(len(eval_transitions[\"android\"].keys()), 2)\n",
    "# print(nRows)\n",
    "# plot_separate_density_curves(ifig, nRows, eval_transitions[\"android\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_density_df = get_location_density_df(eval_transitions[\"ios\"])\n",
    "nRows = get_row_count(len(eval_transitions[\"ios\"].keys()), 2)\n",
    "print(nRows)\n",
    "ios_density_df.plot(kind='density', subplots=False, layout=(nRows, 2), figsize=(10,10), sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ifig, ax) = plt.subplots(nrows=0, ncols=0, figsize=(16,16))\n",
    "# nRows = get_row_count(len(eval_transitions[\"ios\"].keys()), 2)\n",
    "# print(nRows)\n",
    "# plot_separate_density_curves(ifig, nRows, eval_transitions[\"ios\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loc_df = eval_transitions[\"ios\"][\"ucb-sdb-ios-1\"][\"evaluation_ranges\"][0][\"location_df\"]; test_loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loc_df = eval_transitions[\"ios\"][\"ucb-sdb-ios-2\"][\"evaluation_ranges\"][0][\"location_df\"]; test_loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_vs_power_curves(fig, nRows, phone_map, sel_trip_id):\n",
    "    for i, phone_label in enumerate(phone_map.keys()):\n",
    "        ax = fig.add_subplot(nRows, 2, i+1)\n",
    "        curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "        for r in curr_evaluation_ranges:\n",
    "            if r[\"trip_id\"] == sel_trip_id:\n",
    "                battery_df = r[\"battery_df\"]\n",
    "                location_df = r[\"location_df\"]\n",
    "                battery_df.plot(x=\"hr\", y=\"battery_level_pct\", ax=ax, label=phone_label, sharex=True, sharey=True)\n",
    "                location_df.hr.plot(ax=ax, kind=\"density\", secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16, 16))\n",
    "# plot_density_vs_power_curves(fig, nRows, eval_transitions[\"android\"], CURR_TRIP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16, 16))\n",
    "# plot_density_vs_power_curves(fig, nRows, eval_transitions[\"ios\"], CURR_TRIP_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location points over space (overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_list_for_trip():\n",
    "    map_list = []\n",
    "    for phoneOS, phone_map in eval_transitions.items():\n",
    "        print(\"Processing data for %s phones\" % phoneOS)\n",
    "        for phone_label in phone_map:\n",
    "            curr_evaluation_ranges = phone_map[phone_label][\"evaluation_ranges\"]\n",
    "            for r in curr_evaluation_ranges:\n",
    "                curr_map = folium.Map()\n",
    "                location_df = r[\"location_df\"]\n",
    "                latlng_route_coords = list(zip(location_df.latitude, location_df.longitude))\n",
    "                # print(latlng_route_coords[0:10])\n",
    "                pl = folium.PolyLine(latlng_route_coords,\n",
    "                    popup=\"%s: %s\" % (phoneOS, phone_label))\n",
    "                pl.add_to(curr_map)\n",
    "                curr_bounds = pl.get_bounds()\n",
    "                print(curr_bounds)\n",
    "                top_lat = curr_bounds[0][0]\n",
    "                mid_lng = (curr_bounds[0][1] + curr_bounds[1][1])/2\n",
    "                print(\"midpoint = %s, %s, plotting at %s, %s\" % (top_lat,mid_lng, top_lat, mid_lng))\n",
    "                folium.map.Marker(\n",
    "                    [top_lat, mid_lng],\n",
    "                    icon=fof.DivIcon(\n",
    "                        icon_size=(200,36),\n",
    "                        html='<div style=\"font-size: 12pt; color: green;\">%s %s</div>' % (phone_label, r[\"trip_id\"]))\n",
    "                ).add_to(curr_map)\n",
    "                curr_map.fit_bounds(pl.get_bounds())\n",
    "                map_list.append(curr_map)\n",
    "    return map_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ha_map_list = get_map_list_for_trip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = get_row_count(len(ha_map_list), 2)\n",
    "evaluation_maps = bre.Figure(ratio=\"{}%\".format((rows/4) * 100))\n",
    "for i, curr_map in enumerate(ha_map_list):\n",
    "    evaluation_maps.add_subplot(rows, 2, i+1).add_child(curr_map)\n",
    "evaluation_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in trip-specific information and reorder maps to make it easier to compare tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_trip_specific_battery_and_locations():\n",
    "    for phoneOS, phone_map in eval_transitions.items(): # android, ios\n",
    "        for phone_label in phone_map:\n",
    "            print(\"Filling label %s for OS %s\" % (phone_label, phoneOS))\n",
    "            for r in phone_map[phone_label][\"evaluation_ranges\"]:\n",
    "                # print(r[\"battery_df\"].head())\n",
    "                for tr in r[\"evaluation_trip_ranges\"]:\n",
    "                    query = \"ts > %s & ts <= %s\" % (tr[\"start_ts\"], tr[\"end_ts\"])\n",
    "                    # print(\"%s %s %s\" % (phone_label, tr[\"trip_id\"], query))\n",
    "                    # print(r[\"battery_df\"].query(query).head())\n",
    "                    tr[\"battery_df\"] = r[\"battery_df\"].query(query)\n",
    "                    # print(80 * '~')\n",
    "                    # print(tr[\"battery_df\"])\n",
    "                    tr[\"location_df\"] = r[\"location_df\"].query(query)\n",
    "                    # print(80 * \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_trip_specific_battery_and_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_transitions[\"android\"][\"ucb-sdb-android-1\"][\"evaluation_ranges\"][0][\"battery_df\"].query(\"ts > 1560978591 & ts <= 1560980647\").head()\n",
    "# eval_transitions[\"android\"][\"ucb-sdb-android-1\"][\"evaluation_ranges\"][0][\"evaluation_trip_ranges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comparison_regimes():\n",
    "    comparison_map = {}\n",
    "    for phoneOS, phone_map in eval_transitions.items(): # android, ios\n",
    "        print(\"Processing data for %s phones\" % phoneOS)\n",
    "        comparison_map[phoneOS] = {}\n",
    "        all_eval_ranges = [m[\"evaluation_ranges\"] for m in phone_map.values()]\n",
    "        # all the lengths are equal - i.e. the set of lengths has one entr\n",
    "        assert len(set([len(a) for a in all_eval_ranges])) == 1\n",
    "        for ctuple in zip(*all_eval_ranges):\n",
    "            common_names = set([r[\"eval_common_trip_id\"] for r in ctuple])\n",
    "            assert len(common_names) == 1\n",
    "            common_name = list(common_names)[0]\n",
    "            # print(common_name)\n",
    "            comparison_map[phoneOS][common_name] = {}\n",
    "            \n",
    "            separate_roles = [r[\"eval_role\"] for r in ctuple]\n",
    "            print(separate_roles)\n",
    "\n",
    "            eval_trips_for_range = [r[\"evaluation_trip_ranges\"] for r in ctuple]\n",
    "            # print([len(et) for et in eval_trips_for_range])\n",
    "            assert len(set([len(et) for et in eval_trips_for_range])) == 1\n",
    "            for ctriptuple in zip(*(eval_trips_for_range)):\n",
    "                # print([ctt[\"trip_id\"] for ctt in ctriptuple])\n",
    "                common_trip_ids = set([ctt[\"trip_id\"] for ctt in ctriptuple])\n",
    "                assert(len(common_trip_ids)) == 1\n",
    "                common_trip_id = list(common_trip_ids)[0]\n",
    "                print(common_trip_id)\n",
    "                comparison_map[phoneOS][common_name][common_trip_id] = {}\n",
    "                for cr, ctt in zip(separate_roles, ctriptuple):\n",
    "                    comparison_map[phoneOS][common_name][common_trip_id][cr] = ctt\n",
    "    return comparison_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_map = find_comparison_regimes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison_map[\"android\"].keys())\n",
    "print(comparison_map[\"android\"]['HAHFDC v/s HAMFDC'].keys())\n",
    "print(comparison_map[\"android\"]['HAHFDC v/s HAMFDC']['short_walk_suburb'].keys())\n",
    "print(comparison_map[\"android\"]['HAHFDC v/s HAMFDC']['short_walk_suburb']['HAHFDC'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Battery drain over time (per-trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_trip_evaluation_curves(fig, nRows, phone_map):\n",
    "    i = 0\n",
    "    for curr_eval, curr_eval_trip_map in phone_map.items():\n",
    "        for curr_eval_trip_id, eval_trip_compare_map in curr_eval_trip_map.items():\n",
    "            ax = fig.add_subplot(nRows, 2, i+1, title=curr_eval_trip_id)\n",
    "            i = i+1\n",
    "            for compare_id, compare_tr in eval_trip_compare_map.items():\n",
    "                battery_df = compare_tr[\"battery_df\"]\n",
    "                if len(battery_df) > 0:\n",
    "                    battery_df.plot(x=\"hr\", y=\"battery_level_pct\", ax=ax, label=compare_id, ylim=(0,100), sharey=True)\n",
    "                else:\n",
    "                    print(\"no battery data found for %s %s, skipping\" % (curr_eval, curr_eval_trip_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ifig, ax) = plt.subplots(figsize=(16,16),nrows=0,ncols=0)\n",
    "exp_plot_counts = [len(curr_eval_trip_map.values()) for curr_eval, curr_eval_trip_map in comparison_map[\"android\"].items()]\n",
    "print(exp_plot_counts)\n",
    "nRows = get_row_count(sum(exp_plot_counts), 2)\n",
    "print(nRows)\n",
    "plot_per_trip_evaluation_curves(ifig, nRows, comparison_map[\"ios\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ifig, ax) = plt.subplots(figsize=(16,16),nrows=0,ncols=0)\n",
    "exp_plot_counts = [len(curr_eval_trip_map.values()) for curr_eval, curr_eval_trip_map in comparison_map[\"ios\"].items()]\n",
    "print(exp_plot_counts)\n",
    "nRows = get_row_count(sum(exp_plot_counts), 2)\n",
    "print(nRows)\n",
    "plot_per_trip_evaluation_curves(ifig, nRows, comparison_map[\"android\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location points over space (per-trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_trip_map_list():\n",
    "    map_list = []\n",
    "    color_list = ['blue', 'red', 'purple', 'orange']\n",
    "    for phoneOS, phone_map in comparison_map.items():\n",
    "        print(\"Processing data for %s phones\" % phoneOS)\n",
    "        for curr_eval, curr_eval_trip_map in phone_map.items():\n",
    "            for curr_eval_trip_id, eval_trip_compare_map in curr_eval_trip_map.items():\n",
    "                curr_map = folium.Map()\n",
    "                all_points = []\n",
    "                for i, (compare_id, compare_tr) in enumerate(eval_trip_compare_map.items()):\n",
    "                    if i == len(eval_trip_compare_map) - 1:\n",
    "                        print(\"Skipping the last item (power_control)\")\n",
    "                        continue\n",
    "                    location_df = compare_tr[\"location_df\"]\n",
    "                    latlng_route_coords = list(zip(location_df.latitude, location_df.longitude))\n",
    "                    all_points.extend(latlng_route_coords)\n",
    "                    # print(latlng_route_coords[0:10])\n",
    "                    if len(latlng_route_coords) > 0:\n",
    "                        print(\"Processing %s, %s, %s, found %d locations, adding to map\" %\n",
    "                          (curr_eval, curr_eval_trip_id, compare_id, len(latlng_route_coords)))\n",
    "                        pl = folium.PolyLine(latlng_route_coords,\n",
    "                            popup=\"%s\" % (compare_id), color=color_list[i])\n",
    "                        pl.add_to(curr_map)\n",
    "                    else:\n",
    "                        print(\"Processing %s, %s, %s, found %d locations, skipping\" %\n",
    "                          (curr_eval, curr_eval_trip_id, compare_id, len(latlng_route_coords)))\n",
    "                curr_bounds = ful.get_bounds(all_points)\n",
    "                print(curr_bounds)\n",
    "                top_lat = curr_bounds[0][0]\n",
    "                mid_lng = (curr_bounds[0][1] + curr_bounds[1][1])/2\n",
    "                print(\"for trip %s with %d points, midpoint = %s, %s, plotting at %s, %s\" %\n",
    "                      (curr_eval_trip_id, len(all_points), top_lat,mid_lng, top_lat, mid_lng))\n",
    "                folium.map.Marker(\n",
    "                    [top_lat, mid_lng],\n",
    "                    icon=fof.DivIcon(\n",
    "                        icon_size=(200,36),\n",
    "                        html='<div style=\"font-size: 12pt; color: green;\">%s: %s</div>' % (phoneOS, curr_eval_trip_id))\n",
    "                ).add_to(curr_map)\n",
    "                curr_map.fit_bounds(pl.get_bounds())\n",
    "                map_list.append(curr_map)\n",
    "    return map_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha_map_list = get_per_trip_map_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = get_row_count(len(ha_map_list), 2)\n",
    "print(rows)\n",
    "evaluation_maps = bre.Figure(ratio=\"{}%\".format((rows/4) * 100))\n",
    "for i, curr_map in enumerate(ha_map_list):\n",
    "    # print(\"Adding map %s at %d\" % (curr_map, i))\n",
    "    evaluation_maps.add_subplot(rows, 2, i+1).add_child(curr_map)\n",
    "evaluation_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
