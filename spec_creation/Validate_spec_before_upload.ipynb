{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some basic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.features as fof\n",
    "import folium.utilities as ful\n",
    "import branca.element as bre\n",
    "import json\n",
    "import geojson as gj\n",
    "import arrow\n",
    "\n",
    "import shapely.geometry as shpg\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lonlat_swap(lon_lat):\n",
    "    return list(reversed(lon_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_count(n_maps, cols):\n",
    "    rows = (n_maps / cols)\n",
    "    if (n_maps % cols != 0):\n",
    "        rows = rows + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_marker(loc, disp_color):\n",
    "    if loc[\"geometry\"][\"type\"] == \"Point\":\n",
    "        curr_latlng = lonlat_swap(loc[\"geometry\"][\"coordinates\"])\n",
    "        return folium.Marker(curr_latlng, icon=folium.Icon(color=disp_color),\n",
    "                  popup=\"%s\" % loc[\"properties\"][\"name\"])\n",
    "    elif loc[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "        assert len(loc[\"geometry\"][\"coordinates\"]) == 1,\\\n",
    "            \"Only simple polygons supported!\"\n",
    "        curr_latlng = [lonlat_swap(c) for c in loc[\"geometry\"][\"coordinates\"][0]]\n",
    "        # print(\"Returning polygon for %s\" % curr_latlng)\n",
    "        return folium.PolyLine(curr_latlng, color=disp_color, fill=disp_color,\n",
    "                  popup=\"%s\" % loc[\"properties\"][\"name\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker(loc, disp_color):\n",
    "    if type(loc) == list:\n",
    "        return [get_one_marker(l, disp_color) for l in loc]\n",
    "    else:\n",
    "        print(\"Found single entry, is this expected?\")\n",
    "        return [get_one_marker(loc, disp_color)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_to_validate = json.load(open(\"final_sfbayarea_filled_reroutes/train_bus_ebike_mtv_ucb.filled.reroute.json\"))\n",
    "sensing_configs = json.load(open(\"sensing_regimes.all.specs.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment runs from %s -> %s\" % (arrow.get(spec_to_validate[\"start_ts\"]), arrow.get(spec_to_validate[\"end_ts\"])))\n",
    "start_fmt_time_to_validate = arrow.get(spec_to_validate[\"start_ts\"]).format(\"YYYY-MM-DD\")\n",
    "end_fmt_time_to_validate = arrow.get(spec_to_validate[\"end_ts\"]).format(\"YYYY-MM-DD\")\n",
    "if (start_fmt_time_to_validate != spec_to_validate[\"start_fmt_date\"]):\n",
    "    print(\"VALIDATION FAILED, got start %s, expected %s\" % (start_fmt_time_to_validate, spec_to_validate[\"start_fmt_date\"]))\n",
    "if (end_fmt_time_to_validate != spec_to_validate[\"end_fmt_date\"]):\n",
    "    print(\"VALIDATION FAILED, got end %s, expected %s\" % (end_fmt_time_to_validate, spec_to_validate[\"end_fmt_date\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating calibration trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_for_calibration_test(trip):\n",
    "    curr_map = folium.Map()\n",
    "    if trip[\"start_loc\"] is None or trip[\"end_loc\"] is None:\n",
    "        return curr_map\n",
    "    curr_start = lonlat_swap(trip[\"start_loc\"][\"geometry\"][\"coordinates\"])\n",
    "    curr_end = lonlat_swap(trip[\"end_loc\"][\"geometry\"][\"coordinates\"])\n",
    "    folium.Marker(curr_start, icon=folium.Icon(color=\"green\"),\n",
    "                  popup=\"Start: %s\" % trip[\"start_loc\"][\"properties\"][\"name\"]).add_to(curr_map)\n",
    "    folium.Marker(curr_end, icon=folium.Icon(color=\"red\"),\n",
    "                  popup=\"End: %s\" % trip[\"end_loc\"][\"properties\"][\"name\"]).add_to(curr_map)\n",
    "\n",
    "    folium.PolyLine([curr_start, curr_end], popup=trip[\"id\"]).add_to(curr_map)\n",
    "    curr_map.fit_bounds([curr_start, curr_end])    \n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calibration_tests = spec_to_validate[\"calibration_tests\"]\n",
    "rows = get_row_count(len(calibration_tests), 4)\n",
    "calibration_maps = bre.Figure((rows,4))\n",
    "for i, t in enumerate(calibration_tests):\n",
    "    if t[\"config\"][\"sensing_config\"] != sensing_configs[t[\"config\"][\"id\"]][\"sensing_config\"]:\n",
    "        print(\"Mismatch in config for test\" % t)\n",
    "    curr_map = get_map_for_calibration_test(t)\n",
    "    calibration_maps.add_subplot(rows, 4, i+1).add_child(curr_map)\n",
    "calibration_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating evaluation trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_waypoint_markers(waypoint_coords, curr_map):\n",
    "    for i, wpc in enumerate(waypoint_coords[\"geometry\"][\"coordinates\"]):\n",
    "        folium.map.Marker(\n",
    "            lonlat_swap(wpc), popup=\"%d\" % i,\n",
    "            icon=fof.DivIcon(class_name='leaflet-div-icon')).add_to(curr_map)\n",
    "\n",
    "def get_map_for_travel_leg(trip):\n",
    "    curr_map = folium.Map()\n",
    "    [get_one_marker(loc, \"green\").add_to(curr_map) for loc in trip[\"start_loc\"]]\n",
    "    [get_one_marker(loc, \"red\").add_to(curr_map) for loc in trip[\"end_loc\"]]\n",
    "    \n",
    "    # iterate over all reroutes\n",
    "    for rc in trip[\"route_coords\"]:\n",
    "        coords = rc[\"geometry\"][\"coordinates\"]\n",
    "        print(\"Found %d coordinates for the route\" % (len(coords)))\n",
    "        \n",
    "        latlng_coords = [lonlat_swap(c) for c in coords]\n",
    "        folium.PolyLine(latlng_coords, popup=\"%s: %s\" % (trip[\"mode\"], trip[\"name\"])).add_to(curr_map)\n",
    "        \n",
    "        for i, c in enumerate(latlng_coords):\n",
    "            folium.CircleMarker(c, radius=5, popup=\"%d: %s\" % (i, c)).add_to(curr_map)\n",
    "            \n",
    "        curr_map.fit_bounds(ful.get_bounds(latlng_coords))\n",
    "    \n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_for_shim_leg(trip):\n",
    "    curr_map = folium.Map()\n",
    "    for loc in trip[\"loc\"]:\n",
    "        mkr = get_one_marker(loc, \"purple\")\n",
    "        mkr.add_to(curr_map)\n",
    "        curr_map.fit_bounds(mkr.get_bounds())\n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation_trips = spec_to_validate[\"evaluation_trips\"]\n",
    "map_list = []\n",
    "for t in evaluation_trips:\n",
    "    for l in t[\"legs\"]:\n",
    "        if l[\"type\"] == \"TRAVEL\":\n",
    "            curr_map = get_map_for_travel_leg(l)\n",
    "            map_list.append(curr_map)\n",
    "        else:\n",
    "            curr_map = get_map_for_shim_leg(l)\n",
    "            map_list.append(curr_map)\n",
    "\n",
    "rows = get_row_count(len(map_list), 2)\n",
    "evaluation_maps = bre.Figure(ratio=\"{}%\".format((rows/2) * 100))\n",
    "for i, curr_map in enumerate(map_list):\n",
    "    evaluation_maps.add_subplot(rows, 2, i+1).add_child(curr_map)\n",
    "evaluation_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating start and end polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_start_end_contains(leg):\n",
    "    for rc in leg[\"route_coords\"]:\n",
    "        points = gpd.GeoSeries([shpg.Point(p) for p in rc[\"geometry\"][\"coordinates\"]])\n",
    "        \n",
    "        route_start_ts = rc[\"properties\"][\"valid_start_ts\"]\n",
    "        route_end_ts = rc[\"properties\"][\"valid_end_ts\"]\n",
    "        \n",
    "        # query all start_locs and end_locs where [route_start_ts, route_end_ts] âˆˆ [loc_start_ts, loc_end_ts]\n",
    "        start_locs = [shpg.shape(sl[\"geometry\"]) for sl in leg[\"start_loc\"]\n",
    "                      if route_start_ts >= sl[\"properties\"][\"valid_start_ts\"]\\\n",
    "                      and route_end_ts <= sl[\"properties\"][\"valid_end_ts\"]]\n",
    "        \n",
    "        end_locs = [shpg.shape(el[\"geometry\"]) for el in leg[\"end_loc\"]\n",
    "                    if route_start_ts >= el[\"properties\"][\"valid_start_ts\"]\\\n",
    "                    and route_end_ts <= el[\"properties\"][\"valid_end_ts\"]]\n",
    "        \n",
    "        assert len(start_locs) >= 1\n",
    "        assert len(end_locs) >= 1\n",
    "        \n",
    "        for sl in start_locs:\n",
    "            start_contains = points.apply(lambda p: sl.contains(p))\n",
    "            print(points[start_contains])\n",
    "            \n",
    "            # some of the points are within the start polygon\n",
    "            assert start_contains.any(), leg\n",
    "            \n",
    "            # the first point is within the start polygon\n",
    "            assert start_contains.iloc[0], points.head()\n",
    "            \n",
    "            # points within polygons are contiguous\n",
    "            max_index_diff_start = pd.Series(start_contains[start_contains == True].index).diff().max()\n",
    "            assert pd.isnull(max_index_diff_start) or max_index_diff_start == 1, \"Max diff in index = %s for points %s\" % (gpd.GeoSeries(start_contains[start_contains == True].index).diff().max(), points.head())\n",
    "            \n",
    "        for el in end_locs:\n",
    "            end_contains = points.apply(lambda p: el.contains(p))\n",
    "            print(points[end_contains])\n",
    "            \n",
    "            # some of the points are within the end polygon\n",
    "            assert end_contains.any(), leg\n",
    "        \n",
    "            # the last point is within the end polygon\n",
    "            assert end_contains.iloc[-1], points.tail()\n",
    "        \n",
    "            # points within polygons are contiguous\n",
    "            max_index_diff_end = pd.Series(end_contains[end_contains == True].index).diff().max()\n",
    "            assert pd.isnull(max_index_diff_end) or max_index_diff_end == 1, \"Max diff in index = %s for points %s\" % (gpd.GeoSeries(end_contains[end_contains == True].index).diff().max(), points.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_legs = []\n",
    "for t in evaluation_trips:\n",
    "    for l in t[\"legs\"]:\n",
    "        if l[\"type\"] == \"TRAVEL\" and l[\"id\"] not in invalid_legs:\n",
    "            print(\"Checking leg %s, %s\" % (t[\"id\"], l[\"id\"]))\n",
    "            check_start_end_contains(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating sensing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss in spec_to_validate[\"sensing_settings\"]:\n",
    "    for phoneOS, compare_map in ss.items():\n",
    "        compare_list = compare_map[\"compare\"]\n",
    "        for i, ssc in enumerate(compare_map[\"sensing_configs\"]):\n",
    "            if ssc[\"id\"] != compare_list[i]:\n",
    "                print(\"Mismatch in sensing configurations for %s\" % ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating routes for no duplicate coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_TOL = 1e-5\n",
    "\n",
    "def is_coords_equal(c1, c2):\n",
    "    return abs(c2[0] - c1[0]) < REL_TOL and abs(c2[1] - c1[1]) < REL_TOL\n",
    "\n",
    "for t in evaluation_trips:\n",
    "    for l in t[\"legs\"]:\n",
    "        if l[\"type\"] == \"TRAVEL\":\n",
    "            for rc in l[\"route_coords\"]:\n",
    "                print(\"Checking leg %s, %s between dates %s, %s\" % (t[\"id\"], l[\"id\"], rc[\"properties\"][\"valid_start_fmt_date\"], rc[\"properties\"][\"valid_end_fmt_date\"]))\n",
    "                for i in range(len(rc[\"geometry\"][\"coordinates\"])):\n",
    "                    c1 = rc[\"geometry\"][\"coordinates\"][i]\n",
    "                    for j in range(i + 1, len(rc[\"geometry\"][\"coordinates\"])):\n",
    "                        c2 = rc[\"geometry\"][\"coordinates\"][j]\n",
    "                        if is_coords_equal(c1, c2):\n",
    "                            # print(f\"Found duplicate entry, checking entries {i}...{j}\")\n",
    "                            not_matched_index = -1\n",
    "                            for k in range(i, j+1):\n",
    "                                c3 = rc[\"geometry\"][\"coordinates\"][k]\n",
    "                                if not is_coords_equal(c1, c3):\n",
    "                                    not_matched_index = k\n",
    "                            if not_matched_index != -1:\n",
    "                                assert False, (f\"\\tDuplicates {c1}, {c2} found @ indices {i}, {j} with non-duplicate {not_matched_index} in between\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating overlapping time ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representative test case (should break):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlaps(x):\n",
    "    ranges = sorted([(l[\"properties\"][\"valid_start_ts\"], l[\"properties\"][\"valid_end_ts\"]) for l in x],\n",
    "                     key=lambda c: c[0])\n",
    "    for i, r in enumerate(ranges[:-1]):\n",
    "        assert (ts1 := r[1]) <= (ts2 := ranges[i + 1][0]), f\"Overlapping timestamps: {arrow.get(ts1)}, {arrow.get(ts2)}\"\n",
    "\n",
    "\n",
    "invalid_ranges = [\n",
    "    {\n",
    "        \"properties\": {\n",
    "            \"valid_start_ts\": arrow.get(\"2020-01-01\").timestamp,\n",
    "            \"valid_end_ts\": arrow.get(\"2020-03-30\").timestamp\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"properties\": {\n",
    "            \"valid_start_ts\": arrow.get(\"2019-07-16\").timestamp,\n",
    "            \"valid_end_ts\": arrow.get(\"2020-04-30\").timestamp\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    check_overlaps(invalid_ranges)\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual check of spec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in evaluation_trips:\n",
    "    for l in t[\"legs\"]:\n",
    "        print(\"Checking leg %s, %s\" % (t[\"id\"], l[\"id\"]))\n",
    "        \n",
    "        # check locs for shim legs\n",
    "        if \"loc\" in l:\n",
    "            print(\"\\tChecking shim locs...\")\n",
    "            check_overlaps(l[\"loc\"])\n",
    "        \n",
    "        # check start locs\n",
    "        if \"start_loc\" in l:\n",
    "            print(\"\\tChecking start locs...\")\n",
    "            check_overlaps(l[\"start_loc\"])\n",
    "        \n",
    "        # check end locs\n",
    "        if \"end_loc\" in l:\n",
    "            print(\"\\tChecking end locs...\")\n",
    "            check_overlaps(l[\"end_loc\"])\n",
    "        \n",
    "        # check trajectories\n",
    "        if l[\"type\"] == \"TRAVEL\":\n",
    "            print(\"\\tChecking trajectories...\")\n",
    "            check_overlaps(l[\"route_coords\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
