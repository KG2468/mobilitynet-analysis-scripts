{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ac74aa",
   "metadata": {},
   "source": [
    "# Classification Analysis\n",
    "This notebook will contain classification analysis for both the sensed and pipelined algorithms. Analysis will be preformed in regards for the sensed and pipelined algorthms themselves, as well as the ensemble algorithms. The analysis for the ensemble algorithm will focus on the HAMF android phones and the HAHF iOS phones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c045fb",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and validating data\n",
    "import emeval.input.spec_details as eisd\n",
    "import emeval.input.phone_view as eipv\n",
    "import emeval.input.eval_view as eiev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ea7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emeval.viz.phone_view as ezpv\n",
    "import emeval.viz.eval_view as ezev\n",
    "import emeval.viz.geojson as ezgj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for analysized view\n",
    "import emeval.analysed.phone_view as eapv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c817fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emeval.metrics.segmentation as ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "import arrow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c83454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ef879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For maps\n",
    "import folium\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ef8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier debugging while working on modules\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cdf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sd_and_pv_from_server(trips  = [\"unimodal_trip_car_bike_mtv_la\", \"car_scooter_brex_san_jose\", \"train_bus_ebike_mtv_ucb\"], \n",
    "                                 AUTHOR_EMAIL  = \"shankari@eecs.berkeley.edu\", \n",
    "                                 DATASTORE_LOC = \"http://localhost:8080\", \n",
    "                                 pkl_file_name = None):\n",
    "    sd_l = []\n",
    "    pv_l = []\n",
    "    for trip in trips:\n",
    "        sd = eisd.ServerSpecDetails(DATASTORE_LOC, AUTHOR_EMAIL, trip)\n",
    "        pv = eipv.PhoneView(sd)\n",
    "        sd_l.append(sd)\n",
    "        pv_l.append(pv)\n",
    "    if pkl_file_name:\n",
    "        import pickle\n",
    "        with open(pkl_file_name, 'wb') as outp:\n",
    "            for pv in pv_l:\n",
    "                pickle.dump(pv, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    return sd_l, pv_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_pv_from_pkl(pkl_file_name, \n",
    "                       trips = [\"unimodal_trip_car_bike_mtv_la\", \"car_scooter_brex_san_jose\", \"train_bus_ebike_mtv_ucb\"]):\n",
    "    import pickle\n",
    "    pv_l = []\n",
    "    with open('pv.pkl', 'rb') as inp:\n",
    "        for trip in trips:\n",
    "            pv_l.append(pickle.load(inp))\n",
    "    return pv_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pv_la, pv_sj, pv_ucb) = import_pv_from_pkl('pv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b7b48",
   "metadata": {},
   "source": [
    "### Get the sensed data for each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ems.fill_sensed_section_ranges(pv_la)\n",
    "ems.fill_sensed_section_ranges(pv_sj)\n",
    "ems.fill_sensed_section_ranges(pv_ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425a4a7",
   "metadata": {},
   "source": [
    "## Get sensed timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fa1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trip_ss_and_gts_timeline(pv, os, role):\n",
    "    assert os in ['android', 'ios'], 'UNKNOWN OS'\n",
    "    assert role in ['accuracy_control', 'HAHFDC', 'HAMFDC', 'MAHFDC', 'power_control'], \"UNKNOWN ROLE\"\n",
    "    trips = []\n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        if os != phone_os:\n",
    "            continue\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            if \"control\" in phone_detail_map[\"role\"]:\n",
    "#                 print(\"Ignoring %s phone %s since they are always on\" % (phone_detail_map[\"role\"], phone_label))\n",
    "                continue\n",
    "            # this spec does not have any calibration ranges, but evaluation ranges are actually cooler\n",
    "            for r in phone_detail_map[\"evaluation_ranges\"]:\n",
    "                if r['eval_role_base'] != role:\n",
    "                    continue\n",
    "                for tr in r[\"evaluation_trip_ranges\"]:\n",
    "                    tr_ss  = []\n",
    "                    tr_gts = []\n",
    "                    for ss in tr[\"sensed_section_ranges\"]:\n",
    "                        tr_ss.append(ss)\n",
    "                    for section in tr[\"evaluation_section_ranges\"]:\n",
    "                        section_gt_leg = pv.spec_details.get_ground_truth_for_leg(tr['trip_id_base'],\n",
    "                                                                                  section['trip_id_base'],\n",
    "                                                                                  tr['start_ts'],\n",
    "                                                                                  tr['end_ts'])\n",
    "                        \n",
    "                        if section_gt_leg[\"type\"] == \"WAITING\":\n",
    "#                             print(\"Skipping WAITING section %s %s with potential partway transitions\" %\n",
    "#                                   (tr[\"trip_id\"], section[\"trip_id\"]))\n",
    "                            continue\n",
    "                        ## and now we have the gt mode!\n",
    "                        gts = {'start_ts': section['start_ts'], \n",
    "                               'end_ts': section['end_ts'], \n",
    "                               'mode': section_gt_leg['mode']}\n",
    "                        tr_gts.append(gts)\n",
    "                    # now, we build a timeline for each trip\n",
    "                    trip = tr.copy()\n",
    "                    trip['ss_timeline']  = tr_ss\n",
    "                    trip['gts_timeline'] = tr_gts\n",
    "                    trips.append(trip)\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb504d",
   "metadata": {},
   "source": [
    "## Binary Classification (in seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4365a",
   "metadata": {},
   "source": [
    "#### rab base mode map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d898ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBMM = {\"WALKING\": \"WALKING\",\n",
    "             \"RUNNING\" : \"WALKING\", \n",
    "             \"CYCLING\" : \"CYCLING\",\n",
    "             \"BICYCLING\": \"CYCLING\",\n",
    "             \"ESCOOTER\": \"CYCLING\", \n",
    "             \"AUTOMOTIVE\" : \"AUTOMOTIVE\",\n",
    "             \"BUS\": \"AUTOMOTIVE\",\n",
    "             \"TRAIN\": \"AUTOMOTIVE\",\n",
    "             \"LIGHT_RAIL\": \"AUTOMOTIVE\",\n",
    "             \"SUBWAY\": \"AUTOMOTIVE\",\n",
    "             \"CAR\": \"AUTOMOTIVE\",\n",
    "             \"AIR_OR_HSR\": \"AUTOMOTIVE\",\n",
    "             \"INVALID\" : \"INVALID\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fc525",
   "metadata": {},
   "source": [
    "#### cleaned base mode map\n",
    "\n",
    "e-mission-server.emission.core.wrapper.motionactivity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc453b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBMM = {0 : 'AUTOMOTIVE', \n",
    "        1 : 'CYCLING', \n",
    "        2 : 'WALKING', \n",
    "        3 : 'WALKING', \n",
    "        4 : 'INVALID', \n",
    "        5 : 'WALKING', \n",
    "        7 : 'WALKING', \n",
    "        8 : 'WALKING', \n",
    "        9 : 'INVALID', \n",
    "        10 : 'AUTOMOTIVE', \n",
    "        11 : 'AUTOMOTIVE'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3dfff",
   "metadata": {},
   "source": [
    "#### inferred base mode map\n",
    "\n",
    "e-mission-server.emission.core.wrapper.modeprediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c93a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBMM = {0 : 'INVALID', \n",
    "        1 : 'WALKING', \n",
    "        2 : 'CYCLING', \n",
    "        3 : 'AUTOMOTIVE', \n",
    "        4 : 'TRAIN', \n",
    "        5 : 'AUTOMOTIVE', \n",
    "        6 : 'AUTOMOTIVE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_class_in_sec(os, role, pv, BASE_MODE):\n",
    "    if type(pv) is not list: pv - [pv]\n",
    "    trips = []\n",
    "    for v in pv:\n",
    "        trips.extend(get_trip_ss_and_gts_timeline(v, os, role))\n",
    "    TP, FN, FP, TN = {}, {}, {}, {}\n",
    "    for trip in trips:\n",
    "        for mode in set(BASE_MODE.values()):\n",
    "            for ss in trip['ss_timeline']:\n",
    "#                 print(ss.keys())\n",
    "                if 'data' in ss.keys():\n",
    "                    # taken from emission.core.wrapper.modeprediction\n",
    "                    ss = ss['data']\n",
    "                ss_dur = ss['end_ts'] - ss['start_ts']\n",
    "                gts_dur = 0\n",
    "                for gts in trip['gts_timeline']:\n",
    "                    if ss['end_ts'] >= gts['start_ts'] and ss['start_ts'] <= gts['end_ts']:\n",
    "                        dur = min(ss['end_ts'], gts['end_ts']) - max(ss['start_ts'], gts['start_ts'])\n",
    "                        gts_dur += dur\n",
    "                        if BASE_MODE[mode] == BASE_MODE[ss['mode']] and BASE_MODE[mode] == BASE_MODE[gts['mode']]:\n",
    "                            TP[mode] = TP.setdefault(mode, 0) + dur\n",
    "                            if mode == 'TRAIN':\n",
    "                                pass\n",
    "#                                 print(TP[mode])\n",
    "                        elif BASE_MODE[mode] == BASE_MODE[ss['mode']] and BASE_MODE[mode] != BASE_MODE[gts['mode']]:\n",
    "                            FP[mode] = FP.setdefault(mode, 0) + dur\n",
    "                        elif BASE_MODE[mode] != BASE_MODE[ss['mode']] and BASE_MODE[mode] == BASE_MODE[gts['mode']]:\n",
    "                            FN[mode] = FN.setdefault(mode, 0) + dur\n",
    "                        else:\n",
    "                            TN[mode] = TN.setdefault(mode, 0) + dur\n",
    "                leftover = ss_dur - gts_dur\n",
    "                assert leftover >= 0, f\"ERROR, NEGATIVE LEFTOVER OF {leftover}, NEED TO INVESTIGATE\"\n",
    "                if leftover > 0:\n",
    "                    # invalid base mode maps to NO_GT mode\n",
    "                    if mode == 'INVALID':\n",
    "                        TP[mode] = TP.setdefault(mode, 0) + leftover\n",
    "                    # We have no gts, but our modes are equal, so a false positive\n",
    "                    elif BASE_MODE[mode] == BASE_MODE[ss['mode']]:\n",
    "                        FP[mode] = FP.setdefault(mode, 0) + leftover\n",
    "                    # We have no_gts, but our modes are unequal, so a true negative\n",
    "                    else:\n",
    "                        TN[mode] = TN.setdefault(mode, 0) + leftover\n",
    "    return TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214eb548",
   "metadata": {},
   "source": [
    "#### raw output binary tables\n",
    "BASE MODES = `['WALKING', 'CYCLING', 'AUTOMOTIVE', 'INVALID']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190607f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_raw_data(os):\n",
    "    BASE_MODE = RBMM\n",
    "    df = pd.DataFrame(get_binary_class_in_sec(os, 'HAHFDC', [pv_la, pv_ucb, pv_sj], BASE_MODE)).fillna(0)\n",
    "    df=df.reindex(columns=['WALKING', 'CYCLING', 'AUTOMOTIVE', 'INVALID'])\n",
    "    dic={}\n",
    "    d = df.reset_index(drop=True)\n",
    "    dic['ios'+'\\\\_'+'HAHFDC'] = d\n",
    "    d = pd.concat(dic, axis=1)\n",
    "    d['Classifier'] = ['TP', 'FP', 'FN', 'TN']\n",
    "    print(d.set_index('Classifier').rename_axis(['Title', 'Mode'], axis=1).astype(int).style.to_latex())\n",
    "    df = pd.DataFrame(get_binary_class_in_sec(os, 'HAMFDC', [pv_la, pv_ucb, pv_sj], BASE_MODE)).fillna(0)\n",
    "    df=df.reindex(columns=['WALKING', 'CYCLING', 'AUTOMOTIVE', 'INVALID'])\n",
    "    dic={}\n",
    "    d = df.reset_index(drop=True)\n",
    "    dic['ios'+'\\\\_'+'HAHFDC'] = d\n",
    "    d = pd.concat(dic, axis=1)\n",
    "    d['Classifier'] = ['TP', 'FP', 'FN', 'TN']\n",
    "    print(d.set_index('Classifier').rename_axis(['Title', 'Mode'], axis=1).astype(int).style.to_latex())\n",
    "    df = pd.DataFrame(get_binary_class_in_sec(os, 'MAHFDC', [pv_la, pv_ucb, pv_sj], BASE_MODE)).fillna(0)\n",
    "    df=df.reindex(columns=['WALKING', 'CYCLING', 'AUTOMOTIVE', 'INVALID'])\n",
    "    dic={}\n",
    "    d = df.reset_index(drop=True)\n",
    "    dic['ios'+'\\\\_'+'HAHFDC'] = d\n",
    "    d = pd.concat(dic, axis=1)\n",
    "    d['Classifier'] = ['TP', 'FP', 'FN', 'TN']\n",
    "    print(d.set_index('Classifier').rename_axis(['Title', 'Mode'], axis=1).astype(int).style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c868c",
   "metadata": {},
   "source": [
    "#### random forrest binary tables\n",
    "BASE MODES = `['WALKING', 'CYCLING', 'AUTOMOTIVE', 'INVALID']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_binary(os):\n",
    "    BASE_MODE = IBMM\n",
    "    for role in ['HAHFDC', 'HAMFDC', 'MAHFDC']:\n",
    "        df = pd.DataFrame(get_binary_class_in_sec(os, role, [rfv_la, rfv_ucb, rfv_sj], BASE_MODE)).fillna(0)\n",
    "        df=df.reindex(columns=['WALKING', 'CYCLING', 'AUTOMOTIVE', 'TRAIN', 'INVALID'])\n",
    "        dic={}\n",
    "        d = df.reset_index(drop=True)\n",
    "        dic[os+'\\\\_'+role] = d\n",
    "        d = pd.concat(dic, axis=1)\n",
    "        d['Classifier'] = ['TP', 'FP', 'FN', 'TN']\n",
    "        print(d.set_index('Classifier').rename_axis(['Title', 'Mode'], axis=1).astype(int).style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a496827",
   "metadata": {},
   "source": [
    "# $F_\\beta$ score\n",
    "$$\n",
    "F_\\beta = \\frac {(1 + \\beta^2) \\cdot \\mathrm{true\\ positive} }{(1 + \\beta^2) \\cdot \\mathrm{true\\ positive} + \\beta^2 \\cdot \\mathrm{false\\ negative} + \\mathrm{false\\ positive}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b79f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F_score(os, role, pv, BASE_MODE, beta=1):\n",
    "    assert os in ['android', 'ios'], 'UNKNOWN OS'\n",
    "    assert role in ['accuracy_control', 'HAHFDC', 'HAMFDC', 'MAHFDC', 'power_control'], \"UNKNOWN ROLE\"\n",
    "    (TP, FP, FN, TN) = get_binary_class_in_sec(os, role, pv, BASE_MODE)\n",
    "    F_score = {}\n",
    "    for mode in TP.keys():\n",
    "        numerator   = (1 + beta**2) * TP.setdefault(mode, 0)\n",
    "        denominator = (1+beta**2) * TP.setdefault(mode, 0) + beta**2*FN.setdefault(mode, 0) + FP.setdefault(mode, 0)\n",
    "        F_score[mode] = (numerator)/(denominator)\n",
    "    # initializing K \n",
    "    K = 10\n",
    "    for key in F_score:\n",
    "\n",
    "        # rounding to K using round()\n",
    "        F_score[key] = round(F_score[key], K)\n",
    "    return F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_f_score(os, pv, BASE_MODE):\n",
    "    return ([ (k, round(get_F_score(os, 'HAHFDC', pv, BASE_MODE, beta=1)[k], 4)) for k in get_F_score(os, 'HAHFDC', pv, BASE_MODE, beta=1)],\n",
    "            [ (k, round(get_F_score(os, 'HAMFDC', pv, BASE_MODE, beta=1)[k], 4)) for k in get_F_score(os, 'HAMFDC', pv, BASE_MODE, beta=1)],\n",
    "            [ (k, round(get_F_score(os, 'MAHFDC', pv, BASE_MODE, beta=1)[k], 4)) for k in get_F_score(os, 'MAHFDC', pv, BASE_MODE, beta=1)],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f62c54",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "We will now generate confusion matrices based off OS and role, with the acctual modes as the rows, the predicted modes as the columns, and the entries as the base unit for the duration measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(os, role, pv):\n",
    "    assert os in ['android', 'ios'], 'UNKNOWN OS'\n",
    "    assert role in ['accuracy_control', 'HAHFDC', 'HAMFDC', 'MAHFDC', 'power_control'], \"UNKNOWN ROLE\"\n",
    "    cm_l = []\n",
    "    if type(pv) is not list:\n",
    "        pv = [pv]\n",
    "    trips = []\n",
    "    for v in pv :\n",
    "        trips.extend(get_trip_ss_and_gts_timeline(v, os, role))\n",
    "    for trip in trips:\n",
    "        for ss in trip['ss_timeline']:\n",
    "            if 'data' in ss.keys():\n",
    "                # taken from emission.core.wrapper.modeprediction\n",
    "                ss = ss['data']\n",
    "            \n",
    "            ss_dur = ss['end_ts'] - ss['start_ts']\n",
    "            gts_dur = 0\n",
    "            cm = {}\n",
    "            for gts in trip['gts_timeline']:\n",
    "                if ss['end_ts'] >= gts['start_ts'] and ss['start_ts'] <= gts['end_ts']:\n",
    "                    dur = min(ss['end_ts'], gts['end_ts']) - max(ss['start_ts'], gts['start_ts'])\n",
    "                    gts_dur += dur\n",
    "                    cm[gts['mode']] = cm.setdefault(gts['mode'], 0) + dur\n",
    "            leftover = ss_dur - gts_dur\n",
    "            assert leftover >= 0, f\"ERROR, NEGATIVE LEFTOVER OF {leftover}, NEED TO INVESTIGATE\"\n",
    "            cm['NO_GT'] = cm.setdefault('NO_GT', 0) + leftover\n",
    "            cm['sensed_mode'] = ss['mode']\n",
    "            \n",
    "            cm_l.append(cm)\n",
    "    return cm_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_cm(os):\n",
    "    if os == 'ios':\n",
    "        df = pd.DataFrame(get_confusion_matrix(os, 'HAHFDC', [pv_la, pv_sj, pv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'RUNNING', 'CYCLING', 'AUTOMOTIVE']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix(os, 'HAMFDC', [pv_la, pv_sj, pv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER','CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'RUNNING', 'CYCLING', 'AUTOMOTIVE']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix(os, 'MAHFDC', [pv_la, pv_sj, pv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER','CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'RUNNING', 'AUTOMOTIVE']).style.to_latex())\n",
    "    if os == 'android':\n",
    "        df = pd.DataFrame(get_confusion_matrix(os, 'HAHFDC', [pv_la, pv_sj, pv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER','CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'CYCLING', 'AUTOMOTIVE']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix(os, 'HAMFDC', [pv_la, pv_sj, pv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER','CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'CYCLING', 'AUTOMOTIVE']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix(os, 'MAHFDC', [pv_la, pv_sj, pv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER','CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'CYCLING', 'AUTOMOTIVE']).style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfe8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_cm(os):\n",
    "    if os == 'ios':\n",
    "        df = pd.DataFrame(get_confusion_matrix('ios', 'HAHFDC', [rfv_la, rfv_sj, rfv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'BICYCLING', 'TRAIN', 'CAR', 'AIR_OR_HSR']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix('ios', 'HAMFDC', [rfv_la, rfv_sj, rfv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'BICYCLING', 'CAR', 'AIR_OR_HSR']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix('ios', 'MAHFDC', [rfv_la, rfv_sj, rfv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'BICYCLING', 'CAR']).style.to_latex())\n",
    "    if os == 'android':\n",
    "        df = pd.DataFrame(get_confusion_matrix('android', 'HAHFDC', [rfv_la, rfv_sj, rfv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'BICYCLING', 'CAR', 'AIR_OR_HSR']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix('android', 'HAMFDC', [rfv_la, rfv_sj, rfv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'BICYCLING', 'TRAIN', 'CAR']).style.to_latex())\n",
    "        df = pd.DataFrame(get_confusion_matrix('android', 'MAHFDC', [rfv_la, rfv_sj, rfv_ucb])).groupby('sensed_mode').sum().astype(int)\n",
    "        print(df.reindex(columns=['WALKING', 'BICYCLING', 'ESCOOTER', 'CAR', 'BUS', 'LIGHT_RAIL', 'TRAIN', 'NO_GT'],\n",
    "                   index=['WALKING', 'BICYCLING', 'TRAIN', 'CAR', 'AIR_OR_HSR']).style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4ab8e",
   "metadata": {},
   "source": [
    "## Analyzed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd4179",
   "metadata": {},
   "source": [
    "#### cleaned view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a082a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_la   = eapv.create_analysed_view(pv_la, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "cv_sj   = eapv.create_analysed_view(pv_sj, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "cv_ucb  = eapv.create_analysed_view(pv_ucb, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc72d77",
   "metadata": {},
   "source": [
    "#### inferred view random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea612f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfv_la   = eapv.create_analysed_view(pv_la, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/inferred_section\")\n",
    "rfv_sj   = eapv.create_analysed_view(pv_sj, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/inferred_section\")\n",
    "rfv_ucb  = eapv.create_analysed_view(pv_ucb, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/inferred_section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5f2ef",
   "metadata": {},
   "source": [
    "#### inferred view GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09234d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ccea244",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bb6ab",
   "metadata": {},
   "source": [
    "#### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_binary_raw_data('ios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_binary_raw_data('android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_f_score('ios', [pv_la, pv_sj, pv_ucb], RBMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_f_score('android', [pv_la, pv_sj, pv_ucb], RBMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463edab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_raw_cm('ios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_raw_cm('android')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92124deb",
   "metadata": {},
   "source": [
    "#### Cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27c65e",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rf_binary('ios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a284f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rf_binary('android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_f_score('ios', [rfv_la, rfv_sj, rfv_ucb], IBMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_f_score('android', [rfv_la, rfv_sj, rfv_ucb], IBMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rf_cm('ios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rf_cm('android')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a27cd",
   "metadata": {},
   "source": [
    "#### GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7053d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
