{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and validating data\n",
    "import emeval.input.spec_details as eisd\n",
    "import emeval.input.phone_view as eipv\n",
    "import emeval.input.eval_view as eiev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers\n",
    "import emeval.viz.phone_view as ezpv\n",
    "import emeval.viz.eval_view as ezev\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics helpers\n",
    "import emeval.metrics.dist_calculations as emd\n",
    "import emeval.metrics.reference_trajectory as emr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For computation\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely as shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASTORE_URL = \"http://cardshark.cs.berkeley.edu\"\n",
    "AUTHOR_EMAIL = \"shankari@eecs.berkeley.edu\"\n",
    "sd_la = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"unimodal_trip_car_bike_mtv_la\")\n",
    "sd_sj = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"car_scooter_brex_san_jose\")\n",
    "sd_ucb = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"train_bus_ebike_mtv_ucb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ezpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_la = eipv.PhoneView(sd_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_sj = eipv.PhoneView(sd_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_ucb = eipv.PhoneView(sd_ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygons(pvunp):\n",
    "    \"\"\"\n",
    "    Return GeoSeries of polygons\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    trips = pvunp.spec_details.curr_spec['evaluation_trips']\n",
    "\n",
    "    for trip in trips:\n",
    "        for leg in trip['legs']:\n",
    "            if 'loc' in leg and leg['loc']['geometry']['type'] == 'Polygon':\n",
    "                polygons.append(shp.geometry.Polygon(leg['loc']['geometry']['coordinates'][0]))\n",
    "            if 'end_loc' in leg and leg['end_loc']['geometry']['type'] == 'Polygon':\n",
    "                polygons.append(shp.geometry.Polygon(leg['end_loc']['geometry']['coordinates'][0]))\n",
    "            if 'start_loc' in leg and leg['start_loc']['geometry']['type'] == 'Polygon':\n",
    "                polygons.append(shp.geometry.Polygon(leg['start_loc']['geometry']['coordinates'][0]))\n",
    "    return gpd.GeoSeries(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_point_outside_polygons(loc_row, polygons):\n",
    "    \"\"\"\n",
    "    Utility function to check if a point represented by a row in a location dataframe\n",
    "    is contained within a series of Shapely polygons\n",
    "    \"\"\"\n",
    "    # print(loc_row)\n",
    "    point = loc_row.geometry\n",
    "    inside_polygons = polygons.contains(point)\n",
    "    return not inside_polygons.any()\n",
    "\n",
    "def get_travel_trajectory(df, polygons):\n",
    "    \"\"\" \n",
    "    Filters the dataframe of location points to only include values outside the defined polygons\n",
    "    \"\"\"\n",
    "    geo_df = gpd.GeoDataFrame(\n",
    "        df, geometry=df.apply(lambda lr: shp.geometry.Point(lr.longitude, lr.latitude), axis=1))\n",
    "    geo_df[\"outside_polygons\"] = geo_df.apply(lambda r: is_point_outside_polygons(r, polygons), axis=1)\n",
    "    # return a slice instead of setting a column value\n",
    "    return geo_df.query(\"outside_polygons==True\")\n",
    "\n",
    "def get_gt_linestring(gt_leg):\n",
    "    \"\"\"\n",
    "    Get lat-long corrdinates in ground truth\n",
    "    \"\"\"\n",
    "    if 'route_coords' in gt_leg:\n",
    "        coords = gt_leg['route_coords']['geometry']['coordinates']\n",
    "    else:\n",
    "        coords = []\n",
    "    return shp.geometry.LineString(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial-temporal error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_trajectory_input_tree(pv):\n",
    "    ref_tree = {}\n",
    "    # This is a GeoSeries\n",
    "    # polygons = get_polygons(pv)\n",
    "    \n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            for (r_idx, r) in enumerate(phone_detail_map[\"evaluation_ranges\"]):\n",
    "                if r[\"eval_role_base\"] != \"accuracy_control\":\n",
    "                    continue\n",
    "                for (tr_idx, tr) in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                    for (sr_idx, sr) in enumerate(tr[\"evaluation_section_ranges\"]):\n",
    "                        # This is a Shapely LineString\n",
    "                        section_gt_leg = pv.spec_details.get_ground_truth_for_leg(tr[\"trip_id_base\"], sr[\"trip_id_base\"])\n",
    "                        section_gt_points = get_gt_linestring(section_gt_leg)\n",
    "                        if section_gt_points.is_empty:\n",
    "                            print(\"No ground truth route for %s %s, must be polygon, skipping...\" % (tr[\"trip_id_base\"], sr[\"trip_id_base\"]))\n",
    "                            assert section_gt_leg[\"type\"] != \"TRAVEL\", \"For %s, %s, %s, %s, %s found type %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx, section_gt_leg[\"type\"])\n",
    "                            continue\n",
    "                        if len(sr['location_df']) == 0:\n",
    "                            print(\"No sensed locations found, role = %s skipping...\" % (r[\"eval_role_base\"]))\n",
    "                            # assert r[\"eval_role_base\"] == \"power_control\", \"Found no locations for %s, %s, %s, %s, %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx)\n",
    "                            continue\n",
    "                        \n",
    "                        sec_name = tr[\"trip_id_base\"] + \"/\" + sr[\"trip_id_base\"] + \"_\" + str(r_idx)\n",
    "                        if sec_name not in ref_tree:\n",
    "                            ref_tree[sec_name] = {\n",
    "                                \"trip_id\": tr[\"trip_id_base\"],\n",
    "                                \"section_id\": sr[\"trip_id_base\"],\n",
    "                                \"run\": r_idx,\n",
    "                                \"ground_truth\": {\n",
    "                                    \"leg\": section_gt_leg,\n",
    "                                    \"linestring\": section_gt_points\n",
    "                                }\n",
    "                            }\n",
    "                        \n",
    "                        assert sec_name in ref_tree\n",
    "                        e = ref_tree[sec_name]\n",
    "                        # This is a GeoDataFrame\n",
    "                        # section_measured_points = get_travel_trajectory(sr['location_df'], polygons)\n",
    "                        section_measured_points = sr[\"location_df\"]\n",
    "                        if \"temporal_control\" not in e:\n",
    "                            e[\"temporal_control\"] = {}\n",
    "                            e[\"start_ts\"] = sr[\"start_ts\"]\n",
    "                            e[\"end_ts\"] = sr[\"end_ts\"]\n",
    "                        e[\"temporal_control\"][phone_os] = sr\n",
    "    return ref_tree\n",
    "\n",
    "def fill_ref_tree_entry(pv, e):\n",
    "    print(\"Considering entry %s %s %s\" % (e[\"trip_id\"], e[\"section_id\"], e[\"run\"]))\n",
    "    curr_tz = pv.spec_details.eval_tz\n",
    "    assert \"android\" in e[\"temporal_control\"] and \"ios\" in e[\"temporal_control\"]\n",
    "    e[\"reference_df\"] = emr.final_ref_ensemble(e, 25, tz=curr_tz)\n",
    "\n",
    "def get_reference_trajectory_tree(pv, ref_tree_root):\n",
    "    curr_ref_tree = get_reference_trajectory_input_tree(pv)\n",
    "    ref_tree_root[pv.spec_details.CURR_SPEC_ID] = curr_ref_tree\n",
    "    [fill_ref_tree_entry(pv, e) for e in curr_ref_tree.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_tree = {}\n",
    "get_reference_trajectory_tree(pv_la, ref_tree)\n",
    "get_reference_trajectory_tree(pv_sj, ref_tree)\n",
    "get_reference_trajectory_tree(pv_ucb, ref_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 40075017 # circumference of the earth in meters\n",
    "def get_spatio_temporal_errors(pv):\n",
    "    spatial_error_list = []\n",
    "    # This is a GeoSeries\n",
    "    polygons = get_polygons(pv)\n",
    "    \n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            for (r_idx, r) in enumerate(phone_detail_map[\"evaluation_ranges\"]):\n",
    "                run_errors = []\n",
    "                for (tr_idx, tr) in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                    trip_errors = []\n",
    "                    for (sr_idx, sr) in enumerate(tr[\"evaluation_section_ranges\"]):\n",
    "                        # This is a Shapely LineString\n",
    "                        section_gt_leg = pv.spec_details.get_ground_truth_for_leg(tr[\"trip_id_base\"], sr[\"trip_id_base\"])\n",
    "                        section_gt_points = get_gt_linestring(section_gt_leg)\n",
    "                        if section_gt_points.is_empty:\n",
    "                            print(\"No ground truth route for %s %s, must be polygon, skipping...\" % (tr[\"trip_id_base\"], sr[\"trip_id_base\"]))\n",
    "                            assert section_gt_leg[\"type\"] != \"TRAVEL\", \"For %s, %s, %s, %s, %s found type %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx, section_gt_leg[\"type\"])\n",
    "                            continue\n",
    "                        if len(sr['location_df']) < 2:\n",
    "                            print(\"No sensed locations found, role = %s skipping...\" % (r[\"eval_role_base\"]))\n",
    "                            # assert r[\"eval_role_base\"] == \"power_control\", \"Found no locations for %s, %s, %s, %s, %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx)\n",
    "                            continue\n",
    "\n",
    "                        # This is a GeoDataFrame\n",
    "                        eval_df = emr.get_int_aligned_trajectory(sr['location_df'], tz=pv.spec_details.eval_tz)\n",
    "                        sr[\"resampled_df\"] = eval_df\n",
    "                        spec_name = tr[\"trip_id_base\"]+\"/\"+sr[\"trip_id_base\"]+\"_\"+str(r_idx)\n",
    "                        reference_df = ref_tree[pv.spec_details.CURR_SPEC_ID][spec_name][\"reference_df\"]\n",
    "                        print(\"len(eval_df) = %d, len(reference_df) = %d\" % (len(eval_df), len(reference_df)))\n",
    "                        # Match these up by timestamp\n",
    "                        merged_df = pd.merge(eval_df, reference_df, on=\"ts\", how=\"inner\", suffixes=(\"_e\", \"_r\")).sort_values(by=\"ts\", axis=\"index\")\n",
    "                        merged_df[\"t_distance\"] = gpd.GeoSeries(merged_df.geometry_e).distance(gpd.GeoSeries(merged_df.geometry_r)) * (C/360)\n",
    "                        spatial_error_entries = [{\"phone_os\": phone_os, \"phone_label\": phone_label,\n",
    "                                               \"timeline\": pv.spec_details.CURR_SPEC_ID,\n",
    "                                               \"run\": r_idx, \"role\": r[\"eval_role_base\"],\n",
    "                                               \"trip_id\": tr[\"trip_id_base\"], \"section_id\": sr[\"trip_id_base\"],\n",
    "                                               \"error\": e} for e in merged_df.t_distance]\n",
    "                        spatial_error_list.extend(spatial_error_entries)\n",
    "    return spatial_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_errors_list = []\n",
    "st_errors_list.extend(get_spatio_temporal_errors(pv_la))\n",
    "st_errors_list.extend(get_spatio_temporal_errors(pv_sj))\n",
    "st_errors_list.extend(get_spatio_temporal_errors(pv_ucb))\n",
    "\n",
    "st_errors_df = pd.DataFrame(st_errors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2q_map = {\"power_control\": 0, \"HAMFDC\": 1, \"MAHFDC\": 2, \"HAHFDC\": 3, \"accuracy_control\": 4}\n",
    "q2r_map = {0: \"power\", 1: \"HAMFDC\", 2: \"MAHFDC\", 3: \"HAHFDC\", 4: \"accuracy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df[\"quality\"] = st_errors_df.role.apply(lambda r: r2q_map[r])\n",
    "st_errors_df[\"label\"] = st_errors_df.role.apply(lambda r: r.replace('_control', ''))\n",
    "timeline_list = [\"train_bus_ebike_mtv_ucb\", \"car_scooter_brex_san_jose\", \"unimodal_trip_car_bike_mtv_la\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query('timeline == \"train_bus_ebike_mtv_ucb\" & run == 0 & phone_os == \"android\" & quality == 0').error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig, ax_array = plt.subplots(nrows=2,ncols=3,figsize=(12,6), sharex=False, sharey=False)\n",
    "timeline_list = [\"train_bus_ebike_mtv_ucb\", \"car_scooter_brex_san_jose\", \"unimodal_trip_car_bike_mtv_la\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    st_errors_df.query(\"timeline == @tl & phone_os == 'android' & quality > 0\").boxplot(ax = ax_array[0][i], column=[\"error\"], by=[\"quality\"])\n",
    "    ax_array[0][i].set_title(tl)\n",
    "    st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & quality > 0\").boxplot(ax = ax_array[1][i], column=[\"error\"], by=[\"quality\"])\n",
    "    ax_array[1][i].set_title(\"\")\n",
    "\n",
    "for i, ax in enumerate(ax_array[0]):\n",
    "    ax.set_xticklabels([q2r_map[int(t.get_text())] for t in ax.get_xticklabels()])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "for i, ax in enumerate(ax_array[1]):\n",
    "    ax.set_xticklabels([q2r_map[int(t.get_text())] for t in ax.get_xticklabels()])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "ax_array[0][0].set_ylabel(\"Battery drain (android)\")\n",
    "ax_array[1][0].set_ylabel(\"Battery drain (iOS)\")\n",
    "ifig.suptitle(\"Power v/s quality over multiple timelines\")\n",
    "# ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ifig, ax_array = plt.subplots(nrows=2,ncols=4,figsize=(25,10), sharex=True, sharey=True)\n",
    "timeline_list = [\"train_bus_ebike_mtv_ucb\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    for q in range(1,5):\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'android' & quality == @q\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i][q-1], column=[\"error\"], by=[\"section_id\"])\n",
    "        ax_array[2*i][q-1].tick_params(axis=\"x\", labelrotation=45)\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & quality == @q\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i+1][q-1], column=[\"error\"], by=[\"section_id\"])\n",
    "#        ax_array[i][].set_title(\"\")\n",
    "\n",
    "def make_acronym(s):\n",
    "    ssl = s.split(\"_\")\n",
    "    # print(\"After splitting %s, we get %s\" % (s, ssl))\n",
    "    if len(ssl) == 0 or len(ssl[0]) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return \"\".join([ss[0] for ss in ssl])\n",
    "\n",
    "for q in range(1,5):\n",
    "    ax_array[0][q-1].set_title(q2r_map[q])\n",
    "    curr_ticks = [t.get_text() for t in ax_array[1][q-1].get_xticklabels()]\n",
    "    new_ticks = [make_acronym(t) for t in curr_ticks]\n",
    "    ax_array[1][q-1].set_xticklabels(new_ticks)\n",
    "    \n",
    "print(list(zip(curr_ticks, new_ticks)))\n",
    "# fig.text(0,0,\"%s\"% list(zip(curr_ticks, new_ticks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timeline_list = [\"train_bus_ebike_mtv_ucb\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    unique_sections = st_errors_df.query(\"timeline == @tl\").section_id.unique()\n",
    "    ifig, ax_array = plt.subplots(nrows=2,ncols=len(unique_sections),figsize=(40,10), sharex=True, sharey=False)\n",
    "    for sid, s_name in enumerate(unique_sections):\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'android' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i][sid], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*i][sid].set_title(s_name)\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i+1][sid], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*i+1][sid].set_title(\"\")\n",
    "#        ax_array[i][].set_title(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus only on sections where the max error is > 100 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timeline_list = [\"train_bus_ebike_mtv_ucb\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    unique_sections = pd.Series(st_errors_df.query(\"timeline == @tl\").section_id.unique())\n",
    "    sections_with_outliers_mask = unique_sections.apply(lambda s_name: st_errors_df.query(\"timeline == 'train_bus_ebike_mtv_ucb' & section_id == @s_name\").error.max() > 100)\n",
    "    sections_with_outliers = unique_sections[sections_with_outliers_mask]   \n",
    "    ifig, ax_array = plt.subplots(nrows=4,ncols=len(sections_with_outliers)//2,figsize=(16,12), sharex=True, sharey=False)\n",
    "    for sid, s_name in enumerate(sections_with_outliers):\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'android' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*(sid//6)][sid%6], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*(sid//6)][sid%6].set_title(s_name)\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*(sid//6)+1][sid%6], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*(sid//6)+1][sid%6].set_title(\"\")\n",
    "#        ax_array[i][].set_title(\"\")\n",
    "    ifig.suptitle(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (express bus iOS, MAHFDC)\n",
    "\n",
    "ok, so it looks like the error is non-trivial across all runs, but run #1 is the worst and is responsible for the majority of the outliers. And this is borne out by the map, where on run #1, we end up with points in San Leandro!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'ios' & quality == 2 & section_id == 'express_bus' & error > 500\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'ios' & quality == 2 & section_id == 'express_bus'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"ios\"][\"ucb-sdb-ios-3\"][\"evaluation_ranges\"][1]; ucb_and_back[\"trip_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_trip = ucb_and_back[\"evaluation_trip_ranges\"][2]; print(back_trip[\"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_leg = back_trip[\"evaluation_section_ranges\"][4]; print(eb_leg[\"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_leg = sd_ucb.get_ground_truth_for_leg(back_trip[\"trip_id_base\"], eb_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map = folium.Map()\n",
    "gt_leg_gj = ezpv.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"berkeley_to_mtv_SF_express_bus/express_bus_1\"][\"reference_df\"], color=\"green\")\n",
    "sensed_section_gj = ezpv.get_geojson_for_loc_df(eb_leg[\"resampled_df\"])\n",
    "gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"reference\")\n",
    "gt_leg_gj_points = ezpv.get_point_markers(gt_leg_gj, name=\"reference_points\", color=\"green\")\n",
    "sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"sensed_values\")\n",
    "sensed_leg_gj_points = ezpv.get_point_markers(sensed_section_gj, name=\"sensed_points\", color=\"red\", tz=\"America/Los_Angeles\")\n",
    "curr_map.add_child(gt_leg_gj_feature)\n",
    "curr_map.add_child(gt_leg_gj_points)\n",
    "curr_map.add_child(sensed_leg_gj_feature)\n",
    "curr_map.add_child(sensed_leg_gj_points)\n",
    "curr_map.fit_bounds(sensed_leg_gj_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "curr_map = folium.Map()\n",
    "gt_leg_gj = ezpv.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"berkeley_to_mtv_SF_express_bus/express_bus_1\"][\"reference_df\"], color=\"green\")\n",
    "gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"reference\")\n",
    "gt_leg_gj_points = ezpv.get_point_markers(gt_leg_gj, name=\"reference_points\", color=\"green\")\n",
    "\n",
    "colors = [\"red\", \"yellow\", \"blue\"]\n",
    "for run in range(3):\n",
    "    ucb_and_back = pv_ucb.map()[\"ios\"][\"ucb-sdb-ios-3\"][\"evaluation_ranges\"][run]; ucb_and_back[\"trip_id\"]\n",
    "    back_trip = ucb_and_back[\"evaluation_trip_ranges\"][2]; print(back_trip[\"trip_id\"])\n",
    "    eb_leg = back_trip[\"evaluation_section_ranges\"][4]; print(eb_leg[\"trip_id\"])\n",
    "    sensed_section_gj = ezpv.get_geojson_for_leg(eb_leg)\n",
    "    sensed_section_gj[\"properties\"][\"style\"][\"color\"] = colors[run]\n",
    "    sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"run %s\" % run)\n",
    "    sensed_leg_gj_points = ezpv.get_point_markers(sensed_section_gj, name=\"points for %d\" % run, color=colors[run], tz=\"America/Los_Angeles\")\n",
    "    curr_map.add_child(sensed_leg_gj_feature)\n",
    "    curr_map.add_child(sensed_leg_gj_points)\n",
    "    \n",
    "curr_map.add_child(gt_leg_gj_feature)\n",
    "curr_map.add_child(gt_leg_gj_points)\n",
    "curr_map.fit_bounds(gt_leg_gj_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (commuter rail aboveground android, HAMFDC)\n",
    "\n",
    "Runs along El Camino instead of the Caltrain tracks for a while. Not sure if this is even an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & quality == 1 & section_id == 'commuter_rail_aboveground' & error > 500\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-3\"][\"evaluation_ranges\"][0]; ucb_and_back[\"trip_id\"]\n",
    "to_trip = ucb_and_back[\"evaluation_trip_ranges\"][0]; print(to_trip[\"trip_id\"])\n",
    "train_leg = to_trip[\"evaluation_section_ranges\"][2]; print(train_leg[\"trip_id\"])\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(to_trip[\"trip_id_base\"], train_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map = folium.Map()\n",
    "gt_leg_gj = ezpv.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/commuter_rail_aboveground_0\"][\"reference_df\"], color=\"green\")\n",
    "sensed_section_gj = ezpv.get_geojson_for_leg(train_leg)\n",
    "gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"reference\")\n",
    "gt_leg_gj_points = ezpv.get_point_markers(gt_leg_gj, name=\"reference_points\", color=\"green\")\n",
    "sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"sensed_values\")\n",
    "sensed_leg_gj_points = ezpv.get_point_markers(sensed_section_gj, name=\"sensed_points\", color=\"red\", tz=\"America/Los_Angeles\")\n",
    "curr_map.add_child(gt_leg_gj_feature)\n",
    "curr_map.add_child(gt_leg_gj_points)\n",
    "curr_map.add_child(sensed_leg_gj_feature)\n",
    "curr_map.add_child(sensed_leg_gj_points)\n",
    "curr_map.fit_bounds(sensed_leg_gj_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sections = pd.Series(st_errors_df.query(\"timeline == 'train_bus_ebike_mtv_ucb'\").section_id.unique())\n",
    "sections_with_outliers_mask = unique_sections.apply(lambda s_name: st_errors_df.query(\"timeline == 'train_bus_ebike_mtv_ucb' & section_id == @s_name\").error.max() > 100)\n",
    "unique_sections[sections_with_outliers_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (walk_to_bus android, HAMFDC, HAHFDC)\n",
    "\n",
    "In the spatial-only accuracy, run 0 was the worst, with a zig-zag out to San Francisco. But the error magnitude was only ~ 3k since it wasn't that far from BART. Now that we account for temporal differences, the error is much larger (9k) but it is only a zig zag out to Ashby. I am guessing that the other error got stripped out because there was no matching timestamp. Not going to worry about that for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 1 | quality == 3) & section_id == 'walk_to_bus' & error > 500\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 1 | quality == 3) & section_id == 'walk_to_bus' & error > 500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 1 | quality == 3) & section_id == 'walk_to_bus'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-2\"][\"evaluation_ranges\"][1]; ucb_and_back[\"trip_id\"]\n",
    "to_trip = ucb_and_back[\"evaluation_trip_ranges\"][0]; print(to_trip[\"trip_id\"])\n",
    "wb_leg = to_trip[\"evaluation_section_ranges\"][6]; print(wb_leg[\"trip_id\"])\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(to_trip[\"trip_id_base\"], wb_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "curr_map = folium.Map()\n",
    "gt_leg_gj = ezpv.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/walk_to_bus_0\"][\"reference_df\"], color=\"green\")\n",
    "sensed_section_gj = ezpv.get_geojson_for_leg(wb_leg)\n",
    "gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"ground_truth\")\n",
    "gt_leg_gj_points = ezpv.get_point_markers(gt_leg_gj, name=\"ground_truth_points\", color=\"green\")\n",
    "sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"sensed_values\")\n",
    "sensed_leg_gj_points = ezpv.get_point_markers(sensed_section_gj, name=\"sensed_points\", color=\"red\", tz=\"America/Los_Angeles\")\n",
    "curr_map.add_child(gt_leg_gj_feature)\n",
    "curr_map.add_child(gt_leg_gj_points)\n",
    "curr_map.add_child(sensed_leg_gj_feature)\n",
    "curr_map.add_child(sensed_leg_gj_points)\n",
    "curr_map.fit_bounds(sensed_leg_gj_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (light_rail_below_above_ground, android, accuracy_control)\n",
    "\n",
    "In this case, the spatial error was bad, but the temporal error is not that terrible, mainly because all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & quality == 4 & section_id == 'light_rail_below_above_ground' & error > 100\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 4) & section_id == 'light_rail_below_above_ground'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-2\"][\"evaluation_ranges\"][2]; ucb_and_back[\"trip_id\"]\n",
    "back_trip = ucb_and_back[\"evaluation_trip_ranges\"][2]; print(back_trip[\"trip_id\"])\n",
    "lt_leg = back_trip[\"evaluation_section_ranges\"][7]; print(lt_leg[\"trip_id\"])\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(back_trip[\"trip_id_base\"], lt_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map = folium.Map()\n",
    "gt_leg_gj = ezpv.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"berkeley_to_mtv_SF_express_bus/light_rail_below_above_ground_0\"][\"reference_df\"], color=\"green\")\n",
    "gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"ground_truth\")\n",
    "gt_leg_gj_points = ezpv.get_point_markers(gt_leg_gj, name=\"ground_truth_points\", color=\"green\")\n",
    "\n",
    "colors = [\"red\", \"yellow\", \"blue\"]\n",
    "for run in range(3):\n",
    "    ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-2\"][\"evaluation_ranges\"][run]; ucb_and_back[\"trip_id\"]\n",
    "    back_trip = ucb_and_back[\"evaluation_trip_ranges\"][2]; print(back_trip[\"trip_id\"])\n",
    "    lt_leg = back_trip[\"evaluation_section_ranges\"][7]; print(lt_leg[\"trip_id\"])\n",
    "    sensed_section_gj = ezpv.get_geojson_for_leg(lt_leg)\n",
    "    sensed_section_gj[\"properties\"][\"style\"][\"color\"] = colors[run]\n",
    "    sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"run %s\" % run)\n",
    "    sensed_leg_gj_points = ezpv.get_point_markers(sensed_section_gj, name=\"points for %d\" % run, color=colors[run], tz=\"America/Los_Angeles\")\n",
    "    curr_map.add_child(sensed_leg_gj_feature)\n",
    "    curr_map.add_child(sensed_leg_gj_points)\n",
    "    \n",
    "curr_map.add_child(gt_leg_gj_feature)\n",
    "curr_map.add_child(gt_leg_gj_points)\n",
    "curr_map.fit_bounds(gt_leg_gj_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (subway, android, HAMFDC)\n",
    "\n",
    "This is the poster child for temporal accuracy tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_leg = pv_ucb.map()[\"android\"][\"ucb-sdb-android-3\"][\"evaluation_ranges\"][0][\"evaluation_trip_ranges\"][0][\"evaluation_section_ranges\"][5]\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(\"mtv_to_berkeley_sf_bart\", \"subway_underground\"); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_map = folium.Map()\n",
    "gt_leg_gj = ezpv.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/subway_underground_0\"][\"reference_df\"], color=\"green\")\n",
    "sensed_section_gj = ezpv.get_geojson_for_leg(bart_leg)\n",
    "gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"ground_truth\")\n",
    "gt_leg_gj_points = ezpv.get_point_markers(gt_leg_gj, name=\"ground_truth_points\", color=\"green\")\n",
    "sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"sensed_values\")\n",
    "sensed_leg_gj_points = ezpv.get_point_markers(sensed_section_gj, name=\"sensed_points\", color=\"red\", tz=\"America/Los_Angeles\")\n",
    "curr_map.add_child(gt_leg_gj_feature)\n",
    "curr_map.add_child(gt_leg_gj_points)\n",
    "curr_map.add_child(sensed_leg_gj_feature)\n",
    "curr_map.add_child(sensed_leg_gj_points)\n",
    "curr_map.fit_bounds(sensed_leg_gj_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_leg[\"location_df\"].iloc[70:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 4) & section_id == 'subway_underground'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
